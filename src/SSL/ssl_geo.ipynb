{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSL pipeline (Barlow-Twin) using the geometric embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "#from keras.layers.merge import add\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, Tensor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sartaaj/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CoRE_2019.MOFormer_modded.transformer import Transformer, TransformerRegressor\n",
    "from CoRE_2019.MOFormer_modded.dataset_modded import MOF_ID_Dataset\n",
    "from CoRE_2019.MOFormer_modded.tokenizer.mof_tokenizer import MOFTokenizer\n",
    "import csv\n",
    "import yaml\n",
    "from CoRE_2019.MOFormer_modded.model.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MOFTokenizer(\"CoRE_2019/MOFormer_modded/tokenizer/vocab_full.txt\")\n",
    "config = yaml.load(open(\"CoRE_2019/MOFormer_modded/config_ft_transformer.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "config['dataloader']['randomSeed'] = 0\n",
    "\n",
    "if torch.cuda.is_available() and config['gpu'] != 'cpu':\n",
    "    device = config['gpu']\n",
    "    torch.cuda.set_device(device)\n",
    "    config['cuda'] = True\n",
    "\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    config['cuda'] = False\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sartaaj/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from CoRE_2019.MOFormer_modded.transformer import PositionalEncoding\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "\n",
    "# the XRD and SMILES transformers (main model)\n",
    "batch_size = 64\n",
    "embed_size = 512\n",
    "\n",
    "class TransformerXRD(nn.Module):\n",
    "    def __init__(self, input_features=8192, seq_length=batch_size, transformer_heads=8, transformer_ff_dim=512, mlp_hidden_dim=256):\n",
    "        super(TransformerXRD, self).__init__()\n",
    "        \n",
    "        # Project input features to sequence length dimension\n",
    "        self.input_proj = nn.Linear(input_features, seq_length)\n",
    "        \n",
    "        # Define a single Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=seq_length, nhead=transformer_heads, dim_feedforward=transformer_ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project input features to sequence length dimension\n",
    "        x_proj = self.input_proj(x)\n",
    "        x_proj = x_proj.transpose(0, 1)\n",
    "        \n",
    "        # Pass through the Transformer encoder\n",
    "        transformer_output = self.transformer_encoder(x_proj)\n",
    "        \n",
    "        # Revert to the original format (N, S) for the MLP\n",
    "        transformer_output = transformer_output.transpose(0, 1)\n",
    "        \n",
    "        # Squeeze the output to remove the extra dimension if the output dimension is 1 -> else, consider alternative for multi-output regression tasks; maybe make conditional?\n",
    "        return transformer_output\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.token_encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        # initrange = 0.1\n",
    "        # self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        nn.init.xavier_normal_(self.token_encoder.weight)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.token_encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output[:, 0:1, :] #this was added in by me\n",
    "\n",
    "        return output.squeeze(dim = 1) #this was added in by me\n",
    "        #return output\n",
    "\n",
    "transformer_SMILES = Transformer(**config['Transformer'])\n",
    "transformer_XRD = TransformerXRD()\n",
    "\n",
    "class UnifiedTransformer(nn.Module):\n",
    "    def __init__(self, config, input_features=8192, seq_length=batch_size, transformer_heads=8, transformer_ff_dim=512, mlp_hidden_dim=256):\n",
    "        super(UnifiedTransformer, self).__init__()\n",
    "        \n",
    "        # Initialize Transformer1 with its parameters\n",
    "        self.transformer1 = Transformer(**config['Transformer'])\n",
    "        \n",
    "        # Initialize Transformer2 components\n",
    "        self.transformer2 = TransformerXRD(input_features, seq_length, transformer_heads, transformer_ff_dim, mlp_hidden_dim)\n",
    "\n",
    "        #projector\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(576, mlp_hidden_dim), #used to be mlp_hidden_dim here instead of 576 (output size)\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(mlp_hidden_dim, embed_size) #used to be mlp_hidden_dim here instead of 576 (input size)\n",
    "        )\n",
    "                \n",
    "    def forward(self, xrd, smiles):\n",
    "        transformer1_output = self.transformer1(smiles) #gets output from SMILES transformer -> shape of (batchSize, 512, 512)\n",
    "        transformer2_output = self.transformer2(xrd) #gets output from XRD transformer -> shape of (batchSize, seq_len)\n",
    "\n",
    "        concatenated_tensor_corrected = torch.cat((transformer1_output, transformer2_output), dim=1)\n",
    "        output = self.proj(concatenated_tensor_corrected)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "class TransformerGeo(nn.Module):\n",
    "    \"\"\"\n",
    "    Returns embedding for geometric descriptors\n",
    "    \"\"\"\n",
    "    def __init__(self, input_features=15, seq_length=batch_size, transformer_heads=8, transformer_ff_dim=512, mlp_hidden_dim=256):\n",
    "        super(TransformerGeo, self).__init__()\n",
    "        self.input_proj = nn.Linear(input_features, seq_length)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=seq_length, nhead=transformer_heads, dim_feedforward=transformer_ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(64, mlp_hidden_dim),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(mlp_hidden_dim, embed_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project input features to sequence length dimension\n",
    "        x_proj = self.input_proj(x)\n",
    "        x_proj = x_proj.transpose(0, 1)\n",
    "\n",
    "        transformer_output = self.transformer_encoder(x_proj)\n",
    "        transformer_output = transformer_output.transpose(0, 1)\n",
    "\n",
    "        proj_out = self.proj(transformer_output)\n",
    "        return proj_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SSL/sets/ssl_geo.pickle', 'rb') as handle:\n",
    "    ssl_geo = pickle.load(handle)\n",
    "\n",
    "with open('SSL/sets/ssl_xrd.pickle', 'rb') as handle:\n",
    "    ssl_xrd = pickle.load(handle)\n",
    "\n",
    "with open('SSL/sets/ssl_smiles.pickle', 'rb') as handle:\n",
    "    ssl_smiles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full pretraining set size is 133\n"
     ]
    }
   ],
   "source": [
    "data_size = len(ssl_xrd) #should give 8.5k entries for CoRE-2019\n",
    "print(f'Full pretraining set size is {data_size}')\n",
    "split_ratio = 0.85 #train set %\n",
    "train_size = int(split_ratio * data_size)\n",
    "\n",
    "ssl_xrd_train, ssl_smiles_train, ssl_geo_train = ssl_xrd[:train_size], ssl_smiles[:train_size], ssl_geo[:train_size]\n",
    "ssl_xrd_val, ssl_smiles_val, ssl_geo_val = ssl_xrd[train_size-1::], ssl_smiles[train_size-1::], ssl_geo[train_size-1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 64, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssl_geo_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnifiedTransformer(config=config).to(device)\n",
    "model_g = TransformerGeo().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL.barlow_twins import BarlowTwinsLoss\n",
    "\n",
    "loss = BarlowTwinsLoss(device = device, batch_size = 64, embed_size = embed_size, lambd = 0.0051) #same parameters as in moformer\n",
    "\n",
    "learning_rate = 0.00001\n",
    "optimizer_g = optim.Adam(model_g.parameters(), lr = learning_rate)\n",
    "optimizer_t = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_m = yaml.load(open(\"CoRE_2019/MOFormer_modded/config_multiview.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(model_g.parameters()), lr = config_m['optim']['init_lr'], weight_decay=eval(config_m['optim']['weight_decay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Ensembled Loss : 511.65875109107094, Val. Ensembled Loss : 467.5064188639323\n",
      "###############################\n",
      "Epoch : 2\n",
      "Ensembled Loss : 424.88275065464256, Val. Ensembled Loss : 372.0450846354167\n",
      "###############################\n",
      "Epoch : 3\n",
      "Ensembled Loss : 350.55145344691994, Val. Ensembled Loss : 331.88647024972096\n",
      "###############################\n",
      "Epoch : 4\n",
      "Ensembled Loss : 323.8904832147919, Val. Ensembled Loss : 321.05251057942706\n",
      "###############################\n",
      "Epoch : 5\n",
      "Ensembled Loss : 314.62334853990944, Val. Ensembled Loss : 316.0304042271205\n",
      "###############################\n",
      "Epoch : 6\n",
      "Ensembled Loss : 309.51950991470204, Val. Ensembled Loss : 312.4289768763951\n",
      "###############################\n",
      "Epoch : 7\n",
      "Ensembled Loss : 305.52835785182174, Val. Ensembled Loss : 309.33215186709447\n",
      "###############################\n",
      "Epoch : 8\n",
      "Ensembled Loss : 302.39501034896983, Val. Ensembled Loss : 306.4493916829427\n",
      "###############################\n",
      "Epoch : 9\n",
      "Ensembled Loss : 299.01593233631775, Val. Ensembled Loss : 303.13431658063615\n",
      "###############################\n",
      "Epoch : 10\n",
      "Ensembled Loss : 296.1846318877904, Val. Ensembled Loss : 299.42937651134673\n",
      "###############################\n",
      "Epoch : 11\n",
      "Ensembled Loss : 292.5535761740355, Val. Ensembled Loss : 295.42064703078495\n",
      "###############################\n",
      "Epoch : 12\n",
      "Ensembled Loss : 289.70180896320176, Val. Ensembled Loss : 292.29640125093005\n",
      "###############################\n",
      "Epoch : 13\n",
      "Ensembled Loss : 285.2324575238523, Val. Ensembled Loss : 288.451904296875\n",
      "###############################\n",
      "Epoch : 14\n",
      "Ensembled Loss : 281.900428974523, Val. Ensembled Loss : 285.1719040643601\n",
      "###############################\n",
      "Epoch : 15\n",
      "Ensembled Loss : 277.9740905761719, Val. Ensembled Loss : 282.56936427525113\n",
      "###############################\n",
      "Epoch : 16\n",
      "Ensembled Loss : 274.7388513615701, Val. Ensembled Loss : 280.341799781436\n",
      "###############################\n",
      "Epoch : 17\n",
      "Ensembled Loss : 270.73538397054756, Val. Ensembled Loss : 278.7346002487909\n",
      "###############################\n",
      "Epoch : 18\n",
      "Ensembled Loss : 268.9056854248047, Val. Ensembled Loss : 277.2407037644159\n",
      "###############################\n",
      "Epoch : 19\n",
      "Ensembled Loss : 265.7308631829456, Val. Ensembled Loss : 275.86212448846726\n",
      "###############################\n",
      "Epoch : 20\n",
      "Ensembled Loss : 263.3826121102392, Val. Ensembled Loss : 274.8869396391369\n",
      "###############################\n",
      "Epoch : 21\n",
      "Ensembled Loss : 261.1177211525166, Val. Ensembled Loss : 274.1581268310547\n",
      "###############################\n",
      "Epoch : 22\n",
      "Ensembled Loss : 259.31614698561947, Val. Ensembled Loss : 272.5721217564174\n",
      "###############################\n",
      "Epoch : 23\n",
      "Ensembled Loss : 257.31963449663823, Val. Ensembled Loss : 272.21429225376676\n",
      "###############################\n",
      "Epoch : 24\n",
      "Ensembled Loss : 256.2661666194949, Val. Ensembled Loss : 270.3802032470703\n",
      "###############################\n",
      "Epoch : 25\n",
      "Ensembled Loss : 253.5216659950999, Val. Ensembled Loss : 268.95023672921315\n",
      "###############################\n",
      "Epoch : 26\n",
      "Ensembled Loss : 250.89350269959036, Val. Ensembled Loss : 266.2942882719494\n",
      "###############################\n",
      "Epoch : 27\n",
      "Ensembled Loss : 248.18791428287471, Val. Ensembled Loss : 262.77152433849517\n",
      "###############################\n",
      "Epoch : 28\n",
      "Ensembled Loss : 243.66124232469406, Val. Ensembled Loss : 257.6111137753441\n",
      "###############################\n",
      "Epoch : 29\n",
      "Ensembled Loss : 237.42169054419594, Val. Ensembled Loss : 250.69032360258558\n",
      "###############################\n",
      "Epoch : 30\n",
      "Ensembled Loss : 230.49282728887238, Val. Ensembled Loss : 243.35299173990884\n",
      "###############################\n",
      "Epoch : 31\n",
      "Ensembled Loss : 224.31260384078575, Val. Ensembled Loss : 237.80794997442337\n",
      "###############################\n",
      "Epoch : 32\n",
      "Ensembled Loss : 219.81702443350733, Val. Ensembled Loss : 233.96593221028647\n",
      "###############################\n",
      "Epoch : 33\n",
      "Ensembled Loss : 217.05932077053373, Val. Ensembled Loss : 232.15804399762834\n",
      "###############################\n",
      "Epoch : 34\n",
      "Ensembled Loss : 214.46549164088427, Val. Ensembled Loss : 230.5946313767206\n",
      "###############################\n",
      "Epoch : 35\n",
      "Ensembled Loss : 213.051477347855, Val. Ensembled Loss : 229.58573695591517\n",
      "###############################\n",
      "Epoch : 36\n",
      "Ensembled Loss : 211.8144921496906, Val. Ensembled Loss : 228.46991693405877\n",
      "###############################\n",
      "Epoch : 37\n",
      "Ensembled Loss : 211.04819576297186, Val. Ensembled Loss : 227.70965140206474\n",
      "###############################\n",
      "Epoch : 38\n",
      "Ensembled Loss : 209.87863780333933, Val. Ensembled Loss : 226.55958993094308\n",
      "###############################\n",
      "Epoch : 39\n",
      "Ensembled Loss : 208.86389389713253, Val. Ensembled Loss : 225.85323006766183\n",
      "###############################\n",
      "Epoch : 40\n",
      "Ensembled Loss : 207.67365352664373, Val. Ensembled Loss : 225.22852797735305\n",
      "###############################\n",
      "Epoch : 41\n",
      "Ensembled Loss : 206.6975452794438, Val. Ensembled Loss : 224.50755237397692\n",
      "###############################\n",
      "Epoch : 42\n",
      "Ensembled Loss : 205.25141015516974, Val. Ensembled Loss : 223.60957627069382\n",
      "###############################\n",
      "Epoch : 43\n",
      "Ensembled Loss : 204.52509098559355, Val. Ensembled Loss : 222.6431899297805\n",
      "###############################\n",
      "Epoch : 44\n",
      "Ensembled Loss : 203.17034020888067, Val. Ensembled Loss : 221.2933102562314\n",
      "###############################\n",
      "Epoch : 45\n",
      "Ensembled Loss : 201.99713688403105, Val. Ensembled Loss : 219.97392127627418\n",
      "###############################\n",
      "Epoch : 46\n",
      "Ensembled Loss : 200.40878039334729, Val. Ensembled Loss : 219.37806701660156\n",
      "###############################\n",
      "Epoch : 47\n",
      "Ensembled Loss : 199.13915745557938, Val. Ensembled Loss : 217.16737365722656\n",
      "###############################\n",
      "Epoch : 48\n",
      "Ensembled Loss : 197.85584198268114, Val. Ensembled Loss : 215.50719996861048\n",
      "###############################\n",
      "Epoch : 49\n",
      "Ensembled Loss : 196.3514717574668, Val. Ensembled Loss : 214.1402369907924\n",
      "###############################\n",
      "Epoch : 50\n",
      "Ensembled Loss : 194.57425885495886, Val. Ensembled Loss : 213.1061481294178\n",
      "###############################\n",
      "Epoch : 51\n",
      "Ensembled Loss : 192.92618918629873, Val. Ensembled Loss : 211.2376425606864\n",
      "###############################\n",
      "Epoch : 52\n",
      "Ensembled Loss : 191.50015488346065, Val. Ensembled Loss : 209.18023899623327\n",
      "###############################\n",
      "Epoch : 53\n",
      "Ensembled Loss : 189.11929024215294, Val. Ensembled Loss : 207.3875761486235\n",
      "###############################\n",
      "Epoch : 54\n",
      "Ensembled Loss : 187.68508370998686, Val. Ensembled Loss : 205.6208743140811\n",
      "###############################\n",
      "Epoch : 55\n",
      "Ensembled Loss : 185.1122575607975, Val. Ensembled Loss : 204.43024262927827\n",
      "###############################\n",
      "Epoch : 56\n",
      "Ensembled Loss : 184.0042557167796, Val. Ensembled Loss : 202.88927350725447\n",
      "###############################\n",
      "Epoch : 57\n",
      "Ensembled Loss : 181.56908423499723, Val. Ensembled Loss : 200.83722432454428\n",
      "###############################\n",
      "Epoch : 58\n",
      "Ensembled Loss : 180.2974305279487, Val. Ensembled Loss : 199.52849469866072\n",
      "###############################\n",
      "Epoch : 59\n",
      "Ensembled Loss : 178.04235745320278, Val. Ensembled Loss : 197.90265764508928\n",
      "###############################\n",
      "Epoch : 60\n",
      "Ensembled Loss : 176.27100500596308, Val. Ensembled Loss : 196.2842828659784\n",
      "###############################\n",
      "Epoch : 61\n",
      "Ensembled Loss : 175.03518352677338, Val. Ensembled Loss : 195.1380317324684\n",
      "###############################\n",
      "Epoch : 62\n",
      "Ensembled Loss : 172.4227971439868, Val. Ensembled Loss : 194.9017828078497\n",
      "###############################\n",
      "Epoch : 63\n",
      "Ensembled Loss : 172.12426109651548, Val. Ensembled Loss : 193.15852501278832\n",
      "###############################\n",
      "Epoch : 64\n",
      "Ensembled Loss : 170.38391734435496, Val. Ensembled Loss : 192.61131577264695\n",
      "###############################\n",
      "Epoch : 65\n",
      "Ensembled Loss : 169.45442982901514, Val. Ensembled Loss : 192.6259511311849\n",
      "###############################\n",
      "Epoch : 66\n",
      "Ensembled Loss : 168.61536346705614, Val. Ensembled Loss : 192.10784548804872\n",
      "###############################\n",
      "Epoch : 67\n",
      "Ensembled Loss : 167.52256329291689, Val. Ensembled Loss : 191.62962341308594\n",
      "###############################\n",
      "Epoch : 68\n",
      "Ensembled Loss : 166.27600705307142, Val. Ensembled Loss : 190.87533424014137\n",
      "###############################\n",
      "Epoch : 69\n",
      "Ensembled Loss : 165.74047459965257, Val. Ensembled Loss : 191.15042622884116\n",
      "###############################\n",
      "Epoch : 70\n",
      "Ensembled Loss : 164.58318281595686, Val. Ensembled Loss : 190.92298598516555\n",
      "###############################\n",
      "Epoch : 71\n",
      "Ensembled Loss : 163.76174548663926, Val. Ensembled Loss : 190.49579220726378\n",
      "###############################\n",
      "Epoch : 72\n",
      "Ensembled Loss : 163.08560828825014, Val. Ensembled Loss : 190.50311642601378\n",
      "###############################\n",
      "Epoch : 73\n",
      "Ensembled Loss : 161.98027659728464, Val. Ensembled Loss : 190.72802661714098\n",
      "###############################\n",
      "Epoch : 74\n",
      "Ensembled Loss : 161.23979214018425, Val. Ensembled Loss : 190.46889968145462\n",
      "###############################\n",
      "Epoch : 75\n",
      "Ensembled Loss : 160.6334429715587, Val. Ensembled Loss : 189.8857160295759\n",
      "###############################\n",
      "Epoch : 76\n",
      "Ensembled Loss : 159.91478330899128, Val. Ensembled Loss : 189.99622889927454\n",
      "###############################\n",
      "Epoch : 77\n",
      "Ensembled Loss : 159.70409089485102, Val. Ensembled Loss : 190.39542061941964\n",
      "###############################\n",
      "Epoch : 78\n",
      "Ensembled Loss : 158.8332164393062, Val. Ensembled Loss : 190.28866359165735\n",
      "###############################\n",
      "Epoch : 79\n",
      "Ensembled Loss : 158.31919388222482, Val. Ensembled Loss : 190.18031383696058\n",
      "###############################\n",
      "Epoch : 80\n",
      "Ensembled Loss : 157.74561397586248, Val. Ensembled Loss : 190.25938996814546\n",
      "###############################\n",
      "Epoch : 81\n",
      "Ensembled Loss : 157.68878821989077, Val. Ensembled Loss : 190.38997323172433\n",
      "###############################\n",
      "Epoch : 82\n",
      "Ensembled Loss : 156.84443637544075, Val. Ensembled Loss : 189.86618041992188\n",
      "###############################\n",
      "Epoch : 83\n",
      "Ensembled Loss : 156.2650159987728, Val. Ensembled Loss : 189.74011448451452\n",
      "###############################\n",
      "Epoch : 84\n",
      "Ensembled Loss : 155.1141138667554, Val. Ensembled Loss : 189.381837390718\n",
      "###############################\n",
      "Epoch : 85\n",
      "Ensembled Loss : 155.47998884082895, Val. Ensembled Loss : 189.74726940336683\n",
      "###############################\n",
      "Epoch : 86\n",
      "Ensembled Loss : 154.55972992213427, Val. Ensembled Loss : 189.82879783993675\n",
      "###############################\n",
      "Epoch : 87\n",
      "Ensembled Loss : 154.4578912785623, Val. Ensembled Loss : 189.97507513137091\n",
      "###############################\n",
      "Epoch : 88\n",
      "Ensembled Loss : 153.7318450117533, Val. Ensembled Loss : 189.65234738304503\n",
      "###############################\n",
      "Epoch : 89\n",
      "Ensembled Loss : 153.42054883568687, Val. Ensembled Loss : 189.56865728469123\n",
      "###############################\n",
      "Epoch : 90\n",
      "Ensembled Loss : 152.95567645857818, Val. Ensembled Loss : 189.94108290899368\n",
      "###############################\n",
      "Epoch : 91\n",
      "Ensembled Loss : 152.8569524984444, Val. Ensembled Loss : 190.045166015625\n",
      "###############################\n",
      "Epoch : 92\n",
      "Ensembled Loss : 152.23017262146536, Val. Ensembled Loss : 189.74939836774553\n",
      "###############################\n",
      "Epoch : 93\n",
      "Ensembled Loss : 152.02037561467264, Val. Ensembled Loss : 189.57161240350632\n",
      "###############################\n",
      "Epoch : 94\n",
      "Ensembled Loss : 151.65928555378872, Val. Ensembled Loss : 189.761720203218\n",
      "###############################\n",
      "Epoch : 95\n",
      "Ensembled Loss : 151.51435649500485, Val. Ensembled Loss : 189.69031415666853\n",
      "###############################\n",
      "Epoch : 96\n",
      "Ensembled Loss : 150.76500209031906, Val. Ensembled Loss : 189.43226478213356\n",
      "###############################\n",
      "Epoch : 97\n",
      "Ensembled Loss : 150.62943868721482, Val. Ensembled Loss : 189.84886823381697\n",
      "###############################\n",
      "Epoch : 98\n",
      "Ensembled Loss : 150.0690078060184, Val. Ensembled Loss : 190.0431147984096\n",
      "###############################\n",
      "Epoch : 99\n",
      "Ensembled Loss : 150.39249318890867, Val. Ensembled Loss : 189.38569859095983\n",
      "###############################\n",
      "Epoch : 100\n",
      "Ensembled Loss : 149.7193595413613, Val. Ensembled Loss : 189.3074464343843\n",
      "###############################\n"
     ]
    }
   ],
   "source": [
    "#now, test for 100 epoch?\n",
    "\n",
    "num_epoch = 100\n",
    "loss_history = []\n",
    "val_history = []\n",
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "norm = False #should embeddings be normalized? in crystal-twin, they don't but for barlow-twin, it's in the algorithm\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model_g.train()\n",
    "    model.train()\n",
    "\n",
    "    print(f'Epoch : {epoch + 1}')\n",
    "    loss_ensemble = []\n",
    "    for bn, (geo, xrd, smiles) in enumerate(zip(ssl_geo_train, ssl_xrd_train, ssl_smiles_train)):\n",
    "        geo = torch.tensor(geo, dtype = torch.float).to(device)\n",
    "        \n",
    "        xrd = torch.tensor(xrd, dtype = torch.float).to(device)\n",
    "        smiles = torch.from_numpy(smiles).to(device)\n",
    "        \n",
    "        z_a = model_g(geo) #embedding from transformer geo\n",
    "        z_b = model(xrd, smiles) #embedding from concat. model\n",
    "\n",
    "        if norm == True:\n",
    "            z_a_norm = (z_a - torch.mean(z_a, axis = 0))/torch.std(z_a, axis = 0)\n",
    "            z_b_norm = (z_b - torch.mean(z_b, axis = 0))/torch.std(z_b, axis = 0)\n",
    "        \n",
    "        else:\n",
    "            z_a_norm = z_a\n",
    "            z_b_norm = z_b\n",
    "\n",
    "        loss_calc = loss(z_a_norm, z_b_norm)\n",
    "        loss_ensemble.append(loss_calc.item())\n",
    "\n",
    "        #optimizer_g.zero_grad()\n",
    "        #optimizer_t.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_calc.backward()\n",
    "\n",
    "        #optimizer_g.step()\n",
    "        #optimizer_t.step()\n",
    "        optimizer.step()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    val_ensemble = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model_g.eval()\n",
    "        for bn, (geo, xrd, smiles) in enumerate(zip(ssl_geo_val, ssl_xrd_val, ssl_smiles_val)):\n",
    "            geo = torch.tensor(geo, dtype = torch.float).to(device)\n",
    "            \n",
    "            xrd = torch.tensor(xrd, dtype = torch.float).to(device)\n",
    "            smiles = torch.from_numpy(smiles).to(device)\n",
    "\n",
    "            z_a = model_g(geo)\n",
    "            z_b = model(xrd, smiles)\n",
    "\n",
    "            if norm == True:\n",
    "                z_a_norm = (z_a - torch.mean(z_a, axis = 0))/torch.std(z_a, axis = 0)\n",
    "                z_b_norm = (z_b - torch.mean(z_b, axis = 0))/torch.std(z_b, axis = 0)\n",
    "            else:\n",
    "                z_a_norm = z_a\n",
    "                z_b_norm = z_b\n",
    "            \n",
    "            valid_loss = loss(z_a_norm, z_b_norm)\n",
    "            val_ensemble.append(valid_loss.item())\n",
    "\n",
    "        val_history.append(np.mean(val_ensemble))\n",
    "        if np.mean(val_ensemble) < best_valid_loss:\n",
    "            best_valid_loss = np.mean(val_ensemble)\n",
    "            \n",
    "            #save the models here?\n",
    "            torch.save(model.state_dict(), os.path.join('SSL/pretrained/geometric', 'model_t.pth'))\n",
    "            torch.save(model_g.state_dict(), os.path.join('SSL/pretrained/geometric', 'model_g.pth'))\n",
    "\n",
    "    \n",
    "    loss_history.append(np.mean(loss_ensemble))\n",
    "    print(f'Ensembled Loss : {loss_history[-1]}, Val. Ensembled Loss : {val_history[-1]}')\n",
    "    print('###############################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABgC0lEQVR4nO3deXhU9f328ffMJDPZd5JJIIRVIBD2xaBVFBQQd/y5oUBdqIhWsaJFrVV5KqitdaPa2lZsFa22aCuCiCIoq8gie1glLFmAkEz2ZeY8f5xkIAJKMDOThPt1XedKZs6Zmc+cWnP7XS2GYRiIiIiItFDWQBcgIiIi4ksKOyIiItKiKeyIiIhIi6awIyIiIi2awo6IiIi0aAo7IiIi0qIp7IiIiEiLFhToApoCj8fDwYMHiYyMxGKxBLocEREROQ2GYVBcXExKSgpW66nbbxR2gIMHD5KamhroMkREROQM7Nu3jzZt2pzyvMIOEBkZCZg3KyoqKsDViIiIyOlwuVykpqZ6/46fisIOeLuuoqKiFHZERESamR8bgqIByiIiItKiKeyIiIhIi6awIyIiIi2axuyIiIj4iNvtprq6OtBlNFvBwcHYbLaf/D4KOyIiIo3MMAxyc3MpLCwMdCnNXkxMDE6n8yetg6ewIyIi0sjqgk5iYiJhYWFasPYMGIZBWVkZ+fn5ACQnJ5/xeynsiIiINCK32+0NOvHx8YEup1kLDQ0FID8/n8TExDPu0tIAZRERkUZUN0YnLCwswJW0DHX38aeMfVLYERER8QF1XTWOxriPCjsiIiLSoinsiIiISIumsCMiIiI+065dO1544YWA1qCw40MFpVV8d7iUimp3oEsRERH5QRaL5QePJ5544ozed/Xq1UyYMKFxi20gTT33oSteXsqBwnLm3D2Yvm1jA12OiIjIKeXk5Hh//9e//sXjjz9OVlaW97mIiAjv74Zh4Ha7CQr68RjRqlWrxi30DKhlx4ciQ8x/CEoqagJciYiIBJJhGJRV1QTkMAzjtGp0Op3eIzo6GovF4n28bds2IiMjmT9/Pv369cPhcLB06VJ27drFVVddRVJSEhEREQwYMIDPPvus3vt+vxvLYrHw17/+lWuuuYawsDA6d+7M//73v8a83SdQy44PecNOpcKOiMjZrLzaTfrjCwLy2VueGk6YvXH+3P/617/m97//PR06dCA2NpZ9+/Zx2WWX8bvf/Q6Hw8E//vEPrrjiCrKysmjbtu0p3+fJJ5/k2Wef5bnnnuPll19mzJgx7N27l7i4uEap8/vUsuNDkSHBABRXaBM4ERFp/p566ikuueQSOnbsSFxcHL169eIXv/gFPXr0oHPnzkybNo2OHTv+aEvN+PHjuemmm+jUqRNPP/00JSUlfP311z6rWy07PhThMG9vsbqxRETOaqHBNrY8NTxgn91Y+vfvX+9xSUkJTzzxBB9//DE5OTnU1NRQXl5Odnb2D75Pz549vb+Hh4cTFRXl3QPLFxR2fKiuG0thR0Tk7GaxWBqtKymQwsPD6z1+8MEHWbhwIb///e/p1KkToaGhXHfddVRVVf3g+wQHB9d7bLFY8Hg8jV5vneZ/55uwCI3ZERGRFmzZsmWMHz+ea665BjBber777rvAFnUSGrPjQ1EasyMiIi1Y586dmTNnDuvXr+fbb7/l5ptv9mkLzZkKaNh54oknTli0qGvXrt7zFRUVTJo0ifj4eCIiIhg9ejR5eXn13iM7O5tRo0YRFhZGYmIiU6ZMoaamabSk1I3ZUcuOiIi0RM8//zyxsbEMHjyYK664guHDh9O3b99Al3WCgHdjde/evd6c/OMXKJo8eTIff/wx77//PtHR0dxzzz1ce+21LFu2DAC3282oUaNwOp0sX76cnJwcxo4dS3BwME8//bTfv8v3acyOiIg0R+PHj2f8+PHex0OGDDnpej3t2rVj0aJF9Z6bNGlSvcff79Y62fsUFhaeca2nI+BhJygoCKfTecLzRUVF/O1vf2P27NlcfPHFALzxxht069aNlStXcu655/Lpp5+yZcsWPvvsM5KSkujduzfTpk3j4Ycf5oknnsBut/v769Sj2VgiIiKBF/AxOzt27CAlJYUOHTowZswY73S1NWvWUF1dzbBhw7zXdu3albZt27JixQoAVqxYQUZGBklJSd5rhg8fjsvlYvPmzaf8zMrKSlwuV73DF7TOjoiISOAFNOwMGjSIWbNm8cknn/Dqq6+yZ88efvazn1FcXExubi52u52YmJh6r0lKSiI3NxeA3NzcekGn7nzduVOZPn060dHR3iM1NbVxv1gtraAsIiISeAHtxho5cqT39549ezJo0CDS0tJ47733CA0N9dnnTp06lQceeMD72OVy+STwaMyOiIhI4AW8G+t4MTExnHPOOezcuROn00lVVdUJg5by8vK8Y3ycTucJs7PqHp9sHFAdh8NBVFRUvcMX6sbslFW5cXtObyM2ERERaVxNKuyUlJSwa9cukpOT6devH8HBwXz++efe81lZWWRnZ5OZmQlAZmYmGzdurLfE9MKFC4mKiiI9Pd3v9X9f3aKCoJ3PRUREAiWg3VgPPvggV1xxBWlpaRw8eJDf/va32Gw2brrpJqKjo7n99tt54IEHiIuLIyoqinvvvZfMzEzOPfdcAC699FLS09O59dZbefbZZ8nNzeWxxx5j0qRJOByOQH41ABxBNuxBVqpqPBRXVhMdFvzjLxIREZFGFdCws3//fm666SaOHDlCq1atOP/881m5ciWtWrUC4I9//CNWq5XRo0dTWVnJ8OHD+dOf/uR9vc1mY+7cuUycOJHMzEzCw8MZN24cTz31VKC+0gmiQoI4XFKlcTsiIiIBEtCw8+677/7g+ZCQEGbOnMnMmTNPeU1aWhrz5s1r7NIaTYTDDDuakSUiIi3dkCFD6N27Ny+88EKgS6mnSY3ZaYm01o6IiDQHV1xxBSNGjDjpua+++gqLxcKGDRv8XFXjUNjxMa2iLCIizcHtt9/OwoUL2b9//wnn3njjDfr370/Pnj0DUNlPp7DjY1pYUEREmoPLL7+cVq1aMWvWrHrPl5SU8P7773P11Vdz00030bp1a8LCwsjIyOCdd94JTLENpLDjYxFaWFBERAwDqkoDc5xk482TCQoKYuzYscyaNaveZp3vv/8+brebW265hX79+vHxxx+zadMmJkyYwK233srXX3/tq7vWaAK+EWhLF1U7Zkfr7IiInMWqy+DplMB89iMHwR5+WpfedtttPPfccyxZsoQhQ4YAZhfW6NGjSUtL48EHH/Ree++997JgwQLee+89Bg4c6IvKG41adnzs2JgdDVAWEZGmrWvXrgwePJi///3vAOzcuZOvvvqK22+/HbfbzbRp08jIyCAuLo6IiAgWLFjg3cC7KVPLjo95u7E0ZkdE5OwVHGa2sATqsxvg9ttv595772XmzJm88cYbdOzYkQsvvJBnnnmGF198kRdeeIGMjAzCw8O5//77qaqq8lHhjUdhx8e0GaiIiGCxnHZXUqBdf/313HfffcyePZt//OMfTJw4EYvFwrJly7jqqqu45ZZbAPB4PGzfvr1JbM/0Y9SN5WN13VgasyMiIs1BREQEN9xwA1OnTiUnJ4fx48cD0LlzZxYuXMjy5cvZunUrv/jFL07YjLupUtjxsboBysWVGrMjIiLNw+23387Ro0cZPnw4KSnmwOrHHnuMvn37Mnz4cIYMGYLT6eTqq68ObKGnSd1YPlY3ZkctOyIi0lxkZmbWm34OEBcXx4cffviDr1u8eLHvivoJ1LLjYxqzIyIiElgKOz7mnXqu2VgiIiIBobDjY3UbgVbVeKiscQe4GhERkbOPwo6P1bXsgMbtiIiIBILCjo/ZrBbC7TZA43ZERM4m3x/gK2emMe6jwo4fRGjncxGRs0ZwsDl8oaysLMCVtAx197Huvp4JTT33g8iQYPJclbi0P5aISItns9mIiYkhPz8fgLCwMCwWS4Cran4Mw6CsrIz8/HxiYmKw2Wxn/F4KO36gVZRFRM4uTqcTwBt45MzFxMR47+eZUtjxA621IyJydrFYLCQnJ5OYmEh1tVr1z1RwcPBPatGpo7DjB5EasyMiclay2WyN8sdafhqFHV8qzoNKF7HBHvOhxuyIiIj4nWZj+dLfLoFX+tPRswfQKsoiIiKBoLDjS45IAGJslYAGKIuIiASCwo4v2SMAiLJWABqgLCIiEggKO77kMMNOpLW2ZUfdWCIiIn6nsONLtS07EZirP2qAsoiIiP8p7PhSbctOOOWAurFEREQCQWHHlxxRAIQYCjsiIiKBorDjS7XdWCEeM+xozI6IiIj/Kez4Um03lsNjjtkpqaxplK3qRURE5PQp7PhSbctOcE0pAG6PQXm1O5AViYiInHUUdnypdlFBW3UJNqsF0LgdERERf1PY8aXalh1LVQkRDu18LiIiEggKO75U27JD5fFhR2vtiIiI+JPCji/VDlCmqoTIEDPsaEaWiIiIfzWZsDNjxgwsFgv333+/97khQ4ZgsVjqHXfddVe912VnZzNq1CjCwsJITExkypQp1NQ0kUBhP9ayUxd21I0lIiLiX0GBLgBg9erV/PnPf6Znz54nnLvzzjt56qmnvI/DwsK8v7vdbkaNGoXT6WT58uXk5OQwduxYgoODefrpp/1S+w/ytuwUE1nbjaWdz0VERPwr4C07JSUljBkzhtdff53Y2NgTzoeFheF0Or1HVFSU99ynn37Kli1beOutt+jduzcjR45k2rRpzJw5k6qqqlN+ZmVlJS6Xq97hE7UDlDE8xNnNkOPSmB0RERG/CnjYmTRpEqNGjWLYsGEnPf/222+TkJBAjx49mDp1KmVlZd5zK1asICMjg6SkJO9zw4cPx+VysXnz5lN+5vTp04mOjvYeqampjfeFjmcPB8wp53HBZvjSmB0RERH/Cmg31rvvvsvatWtZvXr1Sc/ffPPNpKWlkZKSwoYNG3j44YfJyspizpw5AOTm5tYLOoD3cW5u7ik/d+rUqTzwwAPexy6XyzeBx2IxW3eqiokLrgQ0ZkdERMTfAhZ29u3bx3333cfChQsJCQk56TUTJkzw/p6RkUFycjJDhw5l165ddOzY8Yw/2+Fw4HA4zvj1DfuwSKgqJtZaBVg1ZkdERMTPAtaNtWbNGvLz8+nbty9BQUEEBQWxZMkSXnrpJYKCgnC7T9xWYdCgQQDs3LkTAKfTSV5eXr1r6h47nU4ff4PTVDtIOdpmtuyoG0tERMS/AhZ2hg4dysaNG1m/fr336N+/P2PGjGH9+vXYbLYTXrN+/XoAkpOTAcjMzGTjxo3k5+d7r1m4cCFRUVGkp6f75Xv8qNpBypHWCkADlEVERPwtYN1YkZGR9OjRo95z4eHhxMfH06NHD3bt2sXs2bO57LLLiI+PZ8OGDUyePJkLLrjAO0X90ksvJT09nVtvvZVnn32W3NxcHnvsMSZNmuS/bqofU9uyE2kpB2LVsiMiIuJnTWKdnZOx2+189tlnvPDCC5SWlpKamsro0aN57LHHvNfYbDbmzp3LxIkTyczMJDw8nHHjxtVblyfgahcWDKcc0ABlERERf2tSYWfx4sXe31NTU1myZMmPviYtLY158+b5sKqfqLZlJwyzG0sDlEVERPwr4OvstHi1m4GGesz1gbQRqIiIiH8p7Pha7QBlR23YKa1y4/YYgaxIRETkrKKw42u13Vh297GVnzVIWURExH8UdnytdoCyrboEe5B5uxV2RERE/Edhx9fqdj6vLPHufK5xOyIiIv6jsONrdTufV5UQGWKGHc3IEhER8R+FHV87rmUnIqSuZUdhR0RExF8UdnzNEWX+rCom0hEMQLHG7IiIiPiNwo6v2U/WsqMxOyIiIv6isONr3m6sYo3ZERERCQCFHV+ra9lxVxJtN3/VmB0RERH/UdjxtdrtIgDig6oArbMjIiLiTwo7vmYLBpsDgJjgSgBcGrMjIiLiNwo7/lDbuhNjM8OOxuyIiIj4j8KOP9QOUo6ymmFHY3ZERET8R2HHH2r3x4q2VABQXKluLBEREX9R2PGH2padCGs5AK5yteyIiIj4i8KOP9ROP4/AbNkpKlfLjoiIiL8o7PhDbctOGLUtOxXVeDxGICsSERE5ayjs+EPtbKxQwww7hqH9sURERPxFYccfagcoB1WXEhJs3nKXurJERET8QmHHH47bHys61Nz5XON2RERE/ENhxx/q9seqKlHYERER8TOFHX/wtuyUEBWisCMiIuJPCjv+UDtmh6pj3VgasyMiIuIfCjv+cFzLjrqxRERE/Ethxx8cdS07JUQp7IiIiPiVwo4/2DUbS0REJFAUdvyhrmVH3VgiIiJ+p7DjD8dPPQ8JAhR2RERE/EVhxx/qBihjEBdshhzNxhIREfEPhR1/CA4Di3mrY4OrALXsiIiI+IvCjj9YLN61dqJtlYDCjoiIiL8o7PhLbVdWJObO566KGgzDCGRFIiIiZwWFHX+pHaQcaakAwO0xKK1yB7IiERGRs0KTCTszZszAYrFw//33e5+rqKhg0qRJxMfHExERwejRo8nLy6v3uuzsbEaNGkVYWBiJiYlMmTKFmpoaP1d/GmpbduyeUuw287arK0tERMT3mkTYWb16NX/+85/p2bNnvecnT57MRx99xPvvv8+SJUs4ePAg1157rfe82+1m1KhRVFVVsXz5ct58801mzZrF448/7u+v8ONqW3YsVaXHVlEuU9gRERHxtYCHnZKSEsaMGcPrr79ObGys9/mioiL+9re/8fzzz3PxxRfTr18/3njjDZYvX87KlSsB+PTTT9myZQtvvfUWvXv3ZuTIkUybNo2ZM2dSVVUVqK90ct6FBYuJDtVaOyIiIv4S8LAzadIkRo0axbBhw+o9v2bNGqqrq+s937VrV9q2bcuKFSsAWLFiBRkZGSQlJXmvGT58OC6Xi82bN5/yMysrK3G5XPUOnzt+YUGtoiwiIuI3QYH88HfffZe1a9eyevXqE87l5uZit9uJiYmp93xSUhK5ubnea44POnXn686dyvTp03nyySd/YvUNVK9lxww7WlhQRETE9wLWsrNv3z7uu+8+3n77bUJCQvz62VOnTqWoqMh77Nu3z/cfWreKsvbHEhER8auAhZ01a9aQn59P3759CQoKIigoiCVLlvDSSy8RFBREUlISVVVVFBYW1ntdXl4eTqcTAKfTecLsrLrHddecjMPhICoqqt7hc95uLO18LiIi4k8BCztDhw5l48aNrF+/3nv079+fMWPGeH8PDg7m888/974mKyuL7OxsMjMzAcjMzGTjxo3k5+d7r1m4cCFRUVGkp6f7/Tv9IO18LiIiEhABG7MTGRlJjx496j0XHh5OfHy89/nbb7+dBx54gLi4OKKiorj33nvJzMzk3HPPBeDSSy8lPT2dW2+9lWeffZbc3Fwee+wxJk2ahMPh8Pt3+kHHDVCOUtgRERHxm4AOUP4xf/zjH7FarYwePZrKykqGDx/On/70J+95m83G3LlzmThxIpmZmYSHhzNu3DieeuqpAFZ9CseN2akLO64KhR0RERFfa1JhZ/HixfUeh4SEMHPmTGbOnHnK16SlpTFv3jwfV9YITjIbSy07IiIivhfwdXbOGrW7nmuAsoiIiH8p7PjLSaaea50dERER31PY8ZdTrKBsGEYAixIREWn5FHb8pa5lx11FtN0MONVug/JqdwCLEhERafkUdvylbswOEGaUE2S1ABq3IyIi4msKO/5iC4Igc1sMiwYpi4iI+I3Cjj+dbBXlMoUdERERX1LY8afjBilHqmVHRETELxR2/Olk088ragJYkIiISMunsONPWlhQRETE7xR2/Kley465U4fCjoiIiG8p7PhT3Zid4/bH0irKIiIivqWw4091s7G+t4qyiIiI+I7Cjj9p53MRERG/U9jxp1PsjyUiIiK+o7DjT8cNUI5S2BEREfELhR1/Oq5lJypEYUdERMQfFHb8SWN2RERE/E5hx58cUebPikKiw8ywU1XjoaLaHcCiREREWjaFHX+KSjF/Fh0gwh6E1WI+1Fo7IiIivqOw408xqebP8gKsNWUapCwiIuIHCjv+FBINjmjz98J9GrcjIiLiBwo7/lbXulOYrbAjIiLiBwo7/hbT1vxZpLAjIiLiDwo7/hZd17KzT2N2RERE/EBhx9/qurGKNGZHRETEHxR2/K2uG6swW6soi4iI+IHCjr8d142llh0RERHfU9jxt7qWnZJcYu0GAK7ymgAWJCIi0rIp7PhbWDwEhQKQxGFAKyiLiIj4ksKOv1ks3tadhJo8QN1YIiIivqSwEwi1M7Jiq3MBhR0RERFfUtgJhNpBypEVOYDCjoiIiC8p7ARCbctOaNlBAMqr3VTVeAJZkYiISIulsBMIMWkABBfvw2Ixn1LrjoiIiG8ENOy8+uqr9OzZk6ioKKKiosjMzGT+/Pne80OGDMFisdQ77rrrrnrvkZ2dzahRowgLCyMxMZEpU6ZQU9PEp3LXdmNZivYT6QgCFHZERER8JSiQH96mTRtmzJhB586dMQyDN998k6uuuop169bRvXt3AO68806eeuop72vCwsK8v7vdbkaNGoXT6WT58uXk5OQwduxYgoODefrpp/3+fU5b3ZYRrgPEhlhxVSjsiIiI+EpAW3auuOIKLrvsMjp37sw555zD7373OyIiIli5cqX3mrCwMJxOp/eIiorynvv000/ZsmULb731Fr1792bkyJFMmzaNmTNnUlVVFYivdHoinGANBsNNe4cLAFeFwo6IiIgvNJkxO263m3fffZfS0lIyMzO9z7/99tskJCTQo0cPpk6dSllZmffcihUryMjIICkpyfvc8OHDcblcbN68+ZSfVVlZicvlqnf4ldUK0W0A6GgvAOBQcaV/axARETlLBLQbC2Djxo1kZmZSUVFBREQEH3zwAenp6QDcfPPNpKWlkZKSwoYNG3j44YfJyspizpw5AOTm5tYLOoD3cW5u7ik/c/r06Tz55JM++kanKSYVju6he1gRkEJWbnFg6xEREWmhAh52unTpwvr16ykqKuLf//4348aNY8mSJaSnpzNhwgTvdRkZGSQnJzN06FB27dpFx44dz/gzp06dygMPPOB97HK5SE1N/Unfo8GizVWUOzuOArA1x8+tSyIiImeJgHdj2e12OnXqRL9+/Zg+fTq9evXixRdfPOm1gwYNAmDnzp0AOJ1O8vLy6l1T99jpdJ7yMx0Oh3cGWN3hd7VbRqRYzP2xtua4MAzD/3WIiIi0cAEPO9/n8XiorDz5+JX169cDkJycDEBmZiYbN24kPz/fe83ChQuJiorydoU1WbUzsmKqcrBa4GhZNXkujdsRERFpbAHtxpo6dSojR46kbdu2FBcXM3v2bBYvXsyCBQvYtWsXs2fP5rLLLiM+Pp4NGzYwefJkLrjgAnr27AnApZdeSnp6OrfeeivPPvssubm5PPbYY0yaNAmHwxHIr/bjatfasRXtp2OrCHbkl7A1x4UzOiTAhYmIiLQsAW3Zyc/PZ+zYsXTp0oWhQ4eyevVqFixYwCWXXILdbuezzz7j0ksvpWvXrvzqV79i9OjRfPTRR97X22w25s6di81mIzMzk1tuuYWxY8fWW5enyapba6doP+nOCAC2aNyOiIhIowtoy87f/va3U55LTU1lyZIlP/oeaWlpzJs3rzHL8o+o1mCxgruSvvHV/BeFHREREV9ocmN2zhq2YIhMASAjogjQjCwRERFfUNgJpNqurI52c/r5d4dLKa9yB7IiERGRFueMws6bb77Jxx9/7H380EMPERMTw+DBg9m7d2+jFdfi1U4/j6rMJT7cjseArDwtLigiItKYzijsPP3004SGhgLmlg0zZ87k2WefJSEhgcmTJzdqgS1a3e7nhdl0SzbX+lFXloiISOM6owHK+/bto1OnTgB8+OGHjB49mgkTJnDeeecxZMiQxqyvZfPOyNpHt+RIlu48rLAjIiLSyM6oZSciIoIjR44A5s7jl1xyCQAhISGUl5c3XnUtXW3LDoX71LIjIiLiI2fUsnPJJZdwxx130KdPH7Zv385ll10GwObNm2nXrl1j1teyxaSZP4v2kZ4cCcDWnGI8HgOr1RLAwkRERFqOM2rZmTlzJpmZmRw6dIj//Oc/xMfHA7BmzRpuuummRi2wRYtuY/6sKqFjRDV2m5WSyhr2H1XrmIiISGM5o5admJgYXnnllROef/LJJ39yQWeV4BAIT4TSfIKL99MpMYItOS625LhoGx8W6OpERERahDNq2fnkk09YunSp9/HMmTPp3bs3N998M0ePHm204s4KtdPPObxd43ZERER84IzCzpQpU3C5zD/IGzdu5Fe/+hWXXXYZe/bs4YEHHmjUAlu89heYP795g27ecTsKOyIiIo3ljMLOnj17SE9PB+A///kPl19+OU8//TQzZ85k/vz5jVpgizdwAliDIXs5A4N3A7A1V2FHRESksZxR2LHb7ZSVlQF4dyYHiIuL87b4yGmKSoae1wPQdc+bAOwrKKe4ojqQVYmIiLQYZxR2zj//fB544AGmTZvG119/zahRowDYvn07bdq0adQCzwqZ9wBg3z6XvpGFAGzL1bYRIiIijeGMws4rr7xCUFAQ//73v3n11Vdp3bo1APPnz2fEiBGNWuBZISkdOg0Dw8PEkE8BjdsRERFpLBbDMIxAFxFoLpeL6OhoioqKiIqKCkwRuxfDP66iyhrCgLKXGDmgGzNG9wxMLSIiIs3A6f79PqN1dgDcbjcffvghW7duBaB79+5ceeWV2Gy2M33Ls1v7C8GZgT13I2Nsn7E0p3WgKxIREWkRzqgba+fOnXTr1o2xY8cyZ84c5syZwy233EL37t3ZtWtXY9d4drBYYPAvAfh50AK27T/MpgNFAS5KRESk+TujsPPLX/6Sjh07sm/fPtauXcvatWvJzs6mffv2/PKXv2zsGs8e3a+BqNa0shRxlW0Zv/80K9AViYiINHtnFHaWLFnCs88+S1xcnPe5+Ph4ZsyYwZIlSxqtuLOOLRjOnQjA/UFz2JqVxardRwJclIiISPN2RmHH4XBQXHzi1OiSkhLsdvtPLuqs1nccxKTR2nKY2fbf8Zd5K9AYchERkTN3RmHn8ssvZ8KECaxatQrDMDAMg5UrV3LXXXdx5ZVXNnaNZ5eQKBj3Ee7I1nS05vBw/kN8uW5boKsSERFpts4o7Lz00kt07NiRzMxMQkJCCAkJYfDgwXTq1IkXXnihkUs8C8WmYfv5XFzBrTjHeoDUuTfiLlF3loiIyJn4Sevs7Ny50zv1vFu3bnTq1KnRCvOnJrHOzkkU799KxV9H0IpCCqO7ETPhYwiPD3RZIiIiTcLp/v0+7bDTkN3Mn3/++dO+tiloqmEHYPbchVy6+jYSLC6MyBQso1+HducHuiwREZGAa/RFBdetW3da11ksltN9SzkNV196EePXP8X0qmfoWHwQ480rsFzwEFz4EFi1gKOIiMiP0XYRNO2WHYD/rj/Ar99dyZNBb3J9UO3U/rTz4NrXIVorLYuIyNnpdP9+n9EAZfGvq3q35sHL+/JQzS+4r+puqmxhsHcZvJoJa2aBxxPoEkVERJoshZ1m4vbz2zNleBf+6zmfS8umcSiqO1QUwUf3waxRcEirLYuIiJyMwk4zMumiTtx7cSe+M5I5N//XrO02BYLDIXs5vHoefDEdqisCXaaIiEiTorDTzDxwyTnccX573Ni4dl0fXu3xNkbn4eCphiUz4E/nQtZ80FAsERERQGGn2bFYLDw6qhsTh3QE4JkVZdxe9SBlV/8NIpPh6B5450Z4+zo4vCPA1YqIiASewk4zZLFYeHhEV168sTeOICuLsg5x+ecJ7LlxCZw/GazBsPMz+FMmLHwcqssDXbKIiEjAKOw0Y1f1bs2/7xpMcnQIuw+VcuXr6/mo1QSMu1dCXdfWshfhtZ/B/m8CXa6IiEhAKOw0cxltovnfPefTPy2W4ooa7n1nHXd+fJSDo96Em96FCCcc2QF/uwQ+exJqKgNdsoiIiF8p7LQArSIdzL7zXO4f1plgm4XPtuZzyfNL+EdBNzwTV0DG9WB4YOnz8JeLIHdjoEsWERHxm4CGnVdffZWePXsSFRVFVFQUmZmZzJ8/33u+oqKCSZMmER8fT0REBKNHjyYvL6/ee2RnZzNq1CjCwsJITExkypQp1NTU+PurBJw9yMr9w87h41/+jL5tYyitcvP4fzfzf//Yxp4LX4Ab3oKwBMjfDK8PNRcj1IwtERE5CwQ07LRp04YZM2awZs0avvnmGy6++GKuuuoqNm/eDMDkyZP56KOPeP/991myZAkHDx7k2muv9b7e7XYzatQoqqqqWL58OW+++SazZs3i8ccfD9RXCrhzkiL5912DmXZVd8LtNtbsPcplL37FP4t6HhvL4640FyOcMwEqSwJdsoiIiE81ub2x4uLieO6557juuuto1aoVs2fP5rrrrgNg27ZtdOvWjRUrVnDuuecyf/58Lr/8cg4ePEhSUhIAr732Gg8//DCHDh3Cbref9DMqKyuprDw2dsXlcpGamtpk98Y6UwcKy5ny/rcs33UEgAvOacWz1/bAuekv8PlTYLgh4Rz4vzchKT3A1YqIiDRMs9sby+128+6771JaWkpmZiZr1qyhurqaYcOGea/p2rUrbdu2ZcWKFQCsWLGCjIwMb9ABGD58OC6Xy9s6dDLTp08nOjrae6SmpvruiwVQ65hQ3rp9EL+9Ih1HkJUvtx9i+ItLec8xGs+4uea6PIe3w+sXw6b/BLpcERERnwh42Nm4cSMRERE4HA7uuusuPvjgA9LT08nNzcVutxMTE1Pv+qSkJHJzcwHIzc2tF3TqztedO5WpU6dSVFTkPfbt29e4X6oJsVot/Py89nz8y/PJaB1NUXk1D/1nA1d95GH9qI+g48VQUw7/vg0+n6ZNRUVEpMUJeNjp0qUL69evZ9WqVUycOJFx48axZcsWn36mw+HwDoquO1q6TomRzLl7MI9c1pVIRxAbDxRx9azt3Gd7lJJ+d5sXffV7ePdmqHAFtlgREZFGFPCwY7fb6dSpE/369WP69On06tWLF198EafTSVVVFYWFhfWuz8vLw+l0AuB0Ok+YnVX3uO4aOSbYZmXCBR1Z9OAQbhyQisUC/92Qx4CvL+TrPjPA5oDt8801eY7sCnS5IiIijSLgYef7PB4PlZWV9OvXj+DgYD7//HPvuaysLLKzs8nMzAQgMzOTjRs3kp+f771m4cKFREVFkZ6uAben0irSwYzRPfmodjHC8mo3169oywupL+KJcMKhbeYu6steBPfZN41fRERaloDOxpo6dSojR46kbdu2FBcXM3v2bJ555hkWLFjAJZdcwsSJE5k3bx6zZs0iKiqKe++9F4Dly5cD5qDm3r17k5KSwrPPPktubi633nord9xxB08//fRp13G6o7lbIrfH4NXFO3l+4XY8BvSPq2RWzOtEHDTvMc6ecOVLkNInsIWKiIh8T7OYjZWfn8/YsWPp0qULQ4cOZfXq1d6gA/DHP/6Ryy+/nNGjR3PBBRfgdDqZM2eO9/U2m425c+dis9nIzMzklltuYezYsTz11FOB+krNjs1q4Z6LO/PuhEySo0P4psBB3+x7WdL1txghMZC7wZytteBRqK4IdLkiIiIN1uTW2QmEs7ll53hHS6t48P1v+Xyb2S3YL76aP8W/R1L2x+YFKX3g+n9CTMucqi8iIs1Ls2jZkaYlNtzOX8f155nRGcSH21lzJJhB28fwYuI03I5YOLgO/nwB7Poi0KWKiIicNoUdqcdisXDDgLZ8MWUId5zfniCrhT9md2RYyZMUxnSH8gJ461r46nntrSUiIs2Cwo6cVFRIMI9dns6CyRfws84J7HEnMCh3CttTrjZ3UP/8SXjnRijO+9H3EhERCSSFHflBHVtF8ObPBzJ+cDsqsXPp7v/jk/ZTMWx22P4JzBwIG95TK4+IiDRZCjvyo6xWC7+9Ip0pw7sAFu7amsEL7f+M4ewJFYUw50741y1q5RERkSZJYUdOi8ViYdJFnZhxbQZWC7y4ycHtwc9QMvhhsAbDtrnwp0Gw6s9QU/njbygiIuInCjvSIDcObMurt/TDHmRl0Y6jnL+yP4uHvA/ODCg/CvMfglf6w7fvgscd6HJFREQUdqThhnd38tE959M9JYrCsmrGzyvj3ojnKb3k9xDhhMJs+OAX5pYTWz/STuoiIhJQWlQQLSp4pqrdHl5ZtJNXvtiJ22OQEGHn5eu6knn437D0j1BRZF4Y3wkyJ0GvmyA4NLBFi4hIi3G6f78VdlDY+ak27i/igffWsyO/BKsFpo7sxh39Y7GseAVWv34s9IQlwMA7offNENM2sEWLiEizp7DTAAo7P11FtZtHP9jEf9buB+DKXik8M7onoUYZrHsLVvwJirKPvSClL6RfZR5x7QNUtYiINGcKOw2gsNM4DMPgzeXfMe3jrbg9Bt2So/jLrf1IjQsDdw1s+RC+eQP2LgOO+8fOmQFdLoMuIyG5N1gsAfoGIiLSnCjsNIDCTuNaufsIk95ey5HSKiJDgvjN5en8X782WOpCTHGeOVV9y3/hu6/MFZnrRKZAlxHQ+VJo9zNwRATmS4iISJOnsNMACjuN72BhOXe/vZb1+woBuPCcVjx9bQatY743QLn0COxYAFnzYOciqC49ds4aDGmZ0GkYdBgCielgC/bbdxARkaZNYacBFHZ8o8bt4fWv9vDHz7ZTVeMhwhHE1Mu6cvPAtsdaeY5XXWG29GTNh52fQeHe+udtDnD2MLu6Unqb4Se+I4TG+uPriIhIE6Ow0wAKO761M7+Eh/79LWuzCwEY3j2J56/vTbgj6NQvMgwo2G2Gnh0LYd8qqHSd/NqweHN6e6uucM4I6HgxBIc0/hcREZEmRWGnARR2fM/tMXhj2R6e/SSLKreHrs5IXh/b3xy8fDo8Hji6B3LWw8H1kPMtHNkJrgMnXmuPgM6XQLcroXU/s+XHEamBzyIiLYzCTgMo7PjPmr1H+cU/13C4pJLYsGBmjunL4I4JZ/6GVaVwZJcZfPZ9ba7Y7Np/4nXWYDP0RCZB18uh140Q2+7MP1dERAJOYacBFHb8K6eonAn/WMPGA0XYrBYeHtGFMYPSfrhb63QZBhxcC1v+Zw56ProX3KfYmDTtfOh9k7nWjyPyp3+2iIj4lcJOAyjs+F9FtZuH/7OB/64/CECY3caIHk6u69uGczvEY7U2YpdTVRmUF5gbleZtgW/fgd2L8a71Yw2GdudB5+HmlPeETo332SIi4jMKOw2gsBMYhmHw9qps/rZ0D3sOH5ty3jomlEkXdeLGAamNG3qOV7Tf3Jn923fMLrDjxXWEcydCv/Ga6i4i0oQp7DSAwk5gGYbB2uxC/r1mP3M3HKS4ogaAQe3jmDG6J+0Twn354WbY2b4AdnwKe5eDp9o8F9cBhj4O6VdrcLOISBOksNMACjtNR0W1m7dW7uUPn26nvNqNI8jK5EvO4Y7z2xNks/qhABds+BcseQZKD5nPte4Hl0wzu7pERKTJUNhpAIWdpmdfQRlT52xk6c7DAKQnRzH5knMY1i3x5AsSNrbKYlj+Cix/+diqzpn3mC09QQ7ff76IiPwohZ0GUNhpmgzD4N9r9jNt7hZctV1bXZ2R3H1RJ0ZlJGPz1Xie45Xkw6L/B2vfNB87M2D036HVOb7/bBER+UEKOw2gsNO0HS6p5K9f7eGtlXspqTRDT7v4MH5xYUeu6dOakGCb74vImg8f3m3O6goKhRHTzQHMGssjIhIwCjsNoLDTPBSVVfPmiu/4+7I9FJaZg4hbRTr4+XntGDMojehQH8+ccuXAh3fVTlvHDDuXv6DAIyISIAo7DaCw07yUVtbwztfmlPWcogoAwu02bhrYlhsHptIp0YcLBHo8sOJl+OwJMDxw7t0w/GkFHhGRAFDYaQCFneapqsbDR98e5M9f7mJ7Xon3+Z5torm2T2uu6JVCfISPBhOvexv+e7f5+wUPwcWP+uZzRETklBR2GkBhp3kzDIMvsvKZvSqbxVmHqPGY/0gHWS0M7ZbImEFpnN8pofEXKFz1F5g/xfx92JNw/v2N+/4iIvKDFHYaQGGn5ThcUslH3x5kztoDbDxQ5H0+LT6Mmwe25bp+bRq3teer5+HzJ83fL/s9DLyz8d5bRER+kMJOAyjstExZucW883U2/1mzn+LaWVxBVgvdkqPolRpN79RYeqfG0CEh/Ke1+nw+Db76vfn7rR9Ax4sboXoREfkxCjsNoLDTspVV1TD32xzeWrWXDfuLTjjfLj6Mh0d0ZUQP55ktWGgY8NF95lo8EU6YuBzC4xuhchER+SEKOw2gsHP22H+0jPX7ClmfXcj6fYVsPFBEZY0HgAHtYnlsVDq9UmMa/sZVZfCXC+Hwduh6OdzwlmZoiYj4mMJOAyjsnL1KKmv485JdvP7VbiqqzdBzVe8UHry0C6lxYQ17s5xv4fWh5kaiV7wE/cb5oGIREalzun+//bCz4qlNnz6dAQMGEBkZSWJiIldffTVZWVn1rhkyZAgWi6Xecdddd9W7Jjs7m1GjRhEWFkZiYiJTpkyhpqbGn19FmqkIRxC/urQLXzw4hGv7tgbgv+sPMvQPS3jqoy0UlFad/psl94KhvzF//+TXcHinDyoWEZGGCmjYWbJkCZMmTWLlypUsXLiQ6upqLr30UkpLS+tdd+edd5KTk+M9nn32We85t9vNqFGjqKqqYvny5bz55pvMmjWLxx9/3N9fR5qx5OhQnr++N3PvPZ/BHeOpcnv4+7I9XPDsF7z0+Q5KK08zPGfeC+0vgOoymHMnuKt9W7iIiPyoJtWNdejQIRITE1myZAkXXHABYLbs9O7dmxdeeOGkr5k/fz6XX345Bw8eJCkpCYDXXnuNhx9+mEOHDmG323/0c9WNJcczDIOvdhzmmU+2sfmgC4CECAeTL+nMDf1TCbL9yH8jFB2AVwdDRSH87MFjrT0iItKomkU31vcVFZkzZeLi4uo9//bbb5OQkECPHj2YOnUqZWVl3nMrVqwgIyPDG3QAhg8fjsvlYvPmzSf9nMrKSlwuV71DpI7FYuGCc1rx0T3n89JNfUiLD+NwSSWPfrCJES9+xedb8/jB/0aIbg1XvGD+vvSPcGCNX+oWEZGTazJhx+PxcP/993PeeefRo0cP7/M333wzb731Fl988QVTp07ln//8J7fccov3fG5ubr2gA3gf5+bmnvSzpk+fTnR0tPdITU31wTeS5s5qtXBlrxQWTr6Q316RTmxYMDvzS7j9zW+46fWV7MwvOfWLu18DPa4Dw23ull5d4b/CRUSknibTjTVx4kTmz5/P0qVLadOmzSmvW7RoEUOHDmXnzp107NiRCRMmsHfvXhYsWOC9pqysjPDwcObNm8fIkSNPeI/KykoqKyu9j10uF6mpqerGkh9UVF7Nnxbv5I1l31FV4yEmLJg3xg+gT9vYk7+grABmDoLSfDh/Mgx7wq/1ioi0dM2qG+uee+5h7ty5fPHFFz8YdAAGDRoEwM6d5kwXp9NJXl5evWvqHjudzpO+h8PhICoqqt4h8mOiQ4OZOrIbi351Ib1TYygsq2bMX1fx5fZDJ39BWBxc/kfz92Uvwn51Z4mIBEJAw45hGNxzzz188MEHLFq0iPbt2//oa9avXw9AcnIyAJmZmWzcuJH8/HzvNQsXLiQqKor09HSf1C1ntzaxYbx9xyB+1jmBsio3t7+5mrkbDp784m6XQ8b/geGBDyeqO0tEJAACGnYmTZrEW2+9xezZs4mMjCQ3N5fc3FzKy8sB2LVrF9OmTWPNmjV89913/O9//2Ps2LFccMEF9OzZE4BLL72U9PR0br31Vr799lsWLFjAY489xqRJk3A4GnHDR5HjhDuC+Nu4AVzeM5lqt8G976zjrZV7T37xyGchPBEOZ8Hi6f4tVEREAjtm51T7EL3xxhuMHz+effv2ccstt7Bp0yZKS0tJTU3lmmuu4bHHHqvX9bR3714mTpzI4sWLCQ8PZ9y4ccyYMYOgoKDTqkNTz+VMuT0Gj/93E2+vygbglZv7cHnPlBMv3PYxvHszWKxw64fQ4UL/Fioi0gJpu4gGUNiRn8IwDKbN3crfl+0hzG7jw0nncU5S5IkXfng3rH8bHFFw2yeQ1N3/xYqItCDNaoCySHNmsVh45LKuDO4YT1mVm7v+uQZXxUlWTh71PKSdB5UueOs6KNrv/2JFRM5CCjsijSDIZuXlm/qQEh3C7sOl/Oq9b/F4vtdoGhwCN74NrbpC8UEz8JQXBqReEZGzicKOSCOJj3Dw6i39sNusLNySx6tLdp14UWgsjPk3RCbDoa3wr1ugpvLE60REpNEo7Ig0ol6pMTx1lTkW5/efZp18DZ6YVBjzPtgj4buv4P2fQ+UPrMYsIiI/icKOSCO7cWBbbhqYimHA5H+t51DxSVpunBlwwz/BGgxZH8Nfh8Hhnf4vVkTkLKCwI+IDv72iO12dkRwpreKhf3978o1DO14E4+dChNPs0vrLENg61++1ioi0dAo7Ij4QEmzjxRv7YA+y8kXWoVMvONj2XPjFl9B2MFQVw7/GwMLfQlWpfwsWEWnBFHZEfKSLM5KpI7sC8P8+3sqOvOKTXxiZBOP+B+dOMh8vewF+f465Ls+eL8Hj8U/BIiItlMKOiA+NH9yOC85pRWWNh/veXU9ljfvkF9qCYcTTcN0bENsOqkrMBQjfvAJe7Gm29uxfA1oDVESkwbSCMlpBWXwr31XBiBe/oqC0il9c0IGpl3X74RcYBuxbBetnw+YPzEUI60S1hq6joOvlkDoQgkN9W7yISBOm7SIaQGFHfO3TzblM+OcaAN68bSAXntPq9F5YXQ5Z82Hr/2D7p1B93Fgeiw0S0yGlN7TuC637m49tp7cnnIhIc6ew0wAKO+IPj36wkbdXZRMdGsxH95xP2/iwhr1BdQXsXgxbP4Idn0Jp/onX2COgdT9IHWQeSd0h0gmn2HRXRKQ5U9hpAIUd8YfKGjc3/Hkl6/cV0tUZyZy7BxNmP8NWGMMA10E4uBYOrD328/gurzr2SEjoBPGdIbGbOQMspa+5fYWISDOmsNMACjviLzlF5Vzx8lIOl1RxZa8UXryxN5bGanXxuOHQNnO8z76vYf9qKNgDxkkGRdvskNLHbP1xZkBcR4hrD2FxjVOLiIgfKOw0gMKO+NOq3UcY89dV1HgMHhvVjTt+1sF3H1ZTBUf3wOHt5pHzLWSvhJK8k18fGmsGn9g0iGkLMWnm77HtzcdWm+9qFRFpIIWdBlDYEX97Y9kenvxoCzarhX/ePpDBHRP89+GGYQag7JVmK9DhHXBkF5Tk/vDrbHZzWnx8J4jvCIndwdkDErpAkN0vpYuIHE9hpwEUdsTfDMPgV+99y5x1B4h0BPGXsf3J7Bgf2KIqS6BgtxmECrPh6F7zZ+FeszvMfYrd2a3B0KoLOHtCci9zdlhSD3BE+LV8ETn7KOw0gMKOBEJFtZtxf/+aVXsKsAdZefmmPgzv7gx0WSfncYPrABzZabYCHcqCvM2Qt+nkg6KxQMI50P5n0HGo+dMR6feyRaRlU9hpAIUdCZSKaje/fGcdn27Jw2qB6ddmcMOAtoEu6/QZhtn6k7cJcjaYY4Jy1kNxTv3rrEHmYOgOF5kboKb00fgfEfnJFHYaQGFHAqnG7eHRDzbxr2/2AfDwiK7cdWGHxpulFQjFeXDgG9i1yDwKdtc/HxIN7S+ADkOgVTeISYXIFC2IKCINorDTAAo7EmiGYfDMJ1m8tmQXAD/rnMCjo7rR1dlC/nks2AO7PoddX8Cer6Cy6MRrLDZzO4ykdBhwB3QapsUQReQHKew0gMKONBV/W7qHZ+Zvo8rtwWqBGwakMvmSc0iMbEELALprzK6uXV/A3qVw9DsoOgCe6vrXteoKmZMg43otgCgiJ6Ww0wAKO9KU7D1SyjOfbGPeRnMqeLjdxl0XduS289sT7mih3Twej7n2T2G2uQ/Ymjehqtg8F54IvW+GHteaM77U2iMitRR2GkBhR5qi1d8V8P/mbuHb/WaXT0KEnXsu6sRNg9riCGrhg3sriszAs+o1cxZYnbiO0P0a80jqruAjcpZT2GkAhR1pqjweg482HOQPn24nu6AMgDaxoUwedg6jeiYTEtzCQ4+7GrZ9DJv+Y25+WlNx7FxkCnS62Jza3mGItroQOQsp7DSAwo40dVU1Hv71zT5e+nwHh4rNxf1Cg22c1ymeIV0SuahrIq1jQgNcpY9VFsP2BbBpjjnY+fjgY7GaCxm27nfsaNVF09tFWjiFnQZQ2JHmorzKzazl3zFr+R7yXPVXNO6UGEFmh3jO7RDPoA5xJEQ4AlSlH1SXw97l5rT2nZ/Doa0nXuOIgvSroM8t5ho/6vISaXEUdhpAYUeaG8Mw2JLjYnHWIRZn5bNm71E83/t/cufECLqnRNGxVQQdEyPo2CqCdglhLXO8j+ugucv7gTVwYC0cXAdVJcfOx3eC3mPMgc6RTXSVahFpMIWdBlDYkeauqKyalXuOsGLXEVbuPsK23OKTXme3WcloE83A9nEMbBdH37RYokOD/VytH3jc5kan69+GzR9AtTneCWsQdLsCBtwJaYPV2iPSzCnsNIDCjrQ0R0oqWbP3KDsPlbArv5Rdh0rYlV9CcWVNvessFujUKoKebWLolRpNzzYxdEuObFmtP5XFsPlDWPdPc5f3OondYeAd0OM6CNH/70WaI4WdBlDYkbOBYRjsPVLG198VsHpPAau/K+C7I2UnXGe3WemVGs2g9vEMbG+2/kS0lPV9cjfC16/DxvePtfYEhUDXUdDrJnPvLm1ZIdJsKOw0gMKOnK0OFVeyYX8h3+4vYsP+QjbsL6KgtKreNTarhS5JkWS0jqZHm2gyWkfT1RnZvKe9lxfC+tmwZhYczjr2fHgiZFwHPa+H5N7q5hJp4hR2GkBhR8RkGAbfHSlj9Z4CVu0pYNWeI+w/Wn7CdcE2CwPbx3Fx1ySGdk2kXUJ4AKptBIZhDmbe8C+ztafsyLFzCV3M0JPxfxCbFrgaReSUFHYaQGFH5NQOFpazYX8Rmw4UsfGA+fPI91p/OiSEM7B9HB1ahdM+IYL2CeG0jQvDHmQNUNVnwF0NOz8zg0/W/Prr+LTqZg5oThsMaedBVHLg6hQRL4WdBlDYETl9hmGw53Api7bls2hbPl/vKaDm+/PegSCrhT5tY7igcyt+dk4rMlpHY7M2k26hiiLY+pEZfPZ8BXzv+8V3hi4jzZldrfuDtRmFOpEWRGGnARR2RM6cq6KaZTsOszXHxZ4jZew5XMKeQ6WUVrnrXRcTFsx5HRMY0C6WAe3j6OqMah7hp/QwZK8wFzH8bqk5yPn48BORBF0ug543QNtzNc5HxI+aRdiZPn06c+bMYdu2bYSGhjJ48GCeeeYZunTp4r2moqKCX/3qV7z77rtUVlYyfPhw/vSnP5GUlOS9Jjs7m4kTJ/LFF18QERHBuHHjmD59OkFBpzerQmFHpHEZhsG+gnK+2nmIL7cfYvnOIydMe48MCaJ/WiwXdU1keHcnSVEhAaq2gcoLYfcXsHWuuV9XpevYuaQeMOAOc6yPvZmOYxJpRppF2BkxYgQ33ngjAwYMoKamhkceeYRNmzaxZcsWwsPNf1FMnDiRjz/+mFmzZhEdHc0999yD1Wpl2bJlALjdbnr37o3T6eS5554jJyeHsWPHcuedd/L000+fVh0KOyK+Ve32sH5fIat2H2HVngLW7j1ar+XHYoG+bWMZ2cPJpelO2saHBbDaBqipgu++hE0fmJuV1tQO5nZEQ68boPNwSMtU8BHxkWYRdr7v0KFDJCYmsmTJEi644AKKiopo1aoVs2fP5rrrrgNg27ZtdOvWjRUrVnDuuecyf/58Lr/8cg4ePOht7Xnttdd4+OGHOXToEHa7/YTPqayspLLy2L5CLpeL1NRUhR0RP6lxe9iaU8zyXYf5ZHMu67IL651PjQtlcIcEBneKJ7NjPImRzaDVp/worHsbVv8Vju459rzNbu7N1eFC6HwpOHuqq0ukkTTLsLNz5046d+7Mxo0b6dGjB4sWLWLo0KEcPXqUmJgY73VpaWncf//9TJ48mccff5z//e9/rF+/3nt+z549dOjQgbVr19KnT58TPueJJ57gySefPOF5hR2RwMgpKmfBplzmb8rlm71HcX9vwHPnxAjO65TAeZ0SGNQhjqiQJrzFhcdjblC65UPYvRiK9tU/H9fB3KA0/WpI7qXgI/ITNLuw4/F4uPLKKyksLGTp0qUAzJ49m5///Of1WmEABg4cyEUXXcQzzzzDhAkT2Lt3LwsWLPCeLysrIzw8nHnz5jFy5MgTPkstOyJNV0llDav3FLB812GW7zrClhwXx/9bymqBXqkxDOuWxLBuSZyTFIGlqQYGw4CC3Wbo2bXInNp+/JT22HbHgk9KHwUfkQY63bDTZNZFnzRpEps2bfIGHV9yOBw4HA6ff46INFyEI4iLuiZyUddEAI6WVrFy9xGW7jTDz57DpazLLmRddiHPLciibVwYw7olcVmGk35psU0r+FgsEN/RPAbcDpUl5qDmLR/C9k/h6Hew7EXziGlrBp9zRkDrfhAcGujqRVqMJhF27rnnHubOncuXX35JmzZtvM87nU6qqqooLCys142Vl5eH0+n0XvP111/Xe7+8vDzvORFp3mLD7YzMSGZkhrmQ38HCchZnHeKzrXks3XmY7IIy/r5sD39ftofUuFCu6d2aq/u0pkOriABXfhKOCOhxrXlUldYGn//C9gVQmA3LXzYPa7DZ0tN2ELQZAOGtwB5hDnS2R0BYvPbwEmmAgHZjGYbBvffeywcffMDixYvp3LlzvfN1A5TfeecdRo8eDUBWVhZdu3Y9YYByTk4OiYnmfwn+5S9/YcqUKeTn559WC45mY4k0T2VVNXy5/TCfbs5lwebcejO8eqXGcEXPZC7LSCYlpom3klSVmV1cW/9nLmJYkvvD1zuiIf1Kc4p72vla1FDOWs1izM7dd9/N7Nmz+e9//1tvbZ3o6GhCQ81/OU2cOJF58+Yxa9YsoqKiuPfeewFYvnw5cGzqeUpKCs8++yy5ubnceuut3HHHHZp6LnIWKa9y8+mWXD5Yd4CvdhyuN8i5X1osozKSGdHD2fSDj2FA4V7IXmkuZpjzLVS4zJagqlKoKqHeooaRKWZLUXJviEqB6NYQmQxB6qqXlq9ZhJ1T9a2/8cYbjB8/Hji2qOA777xTb1HB47uo9u7dy8SJE1m8eDHh4eGMGzeOGTNmaFFBkbPUoeJKPt5wkHkbc1m9t6DeAOeuzkhzTFCXRPq2jSHI1sxaRTxuczXnje+ZXWAVRSe/zhHFsS9e+zM0ztzXKzLZDEaRyRDphIhEiHBCZBKExGigtDQbzSLsNBUKOyItV25RBfM35TBvYw5r9h7l+Fnt0aHB3DSwLXf8rD0JEc2wJaSm0hz3kzXfHPNTtB9cB8Fd+eOvPRVHNCR0No/4ThCdai6WWFl87IDa8UO1Y4jsERCeUHu0Mo/vtywZBrirjmuhKgXDY45jckSCPVLjkKTBFHYaQGFH5OxwtLSKL3ccYtG2fJZsP0RhWTUAIcFWbh6YxoQLOuCMbgYLGP4Qw4CyI8dafOpaaeqedx2E4pxjP4tzoSQPivOg8hStRGfCWrcWUu2fGMNjHj8kKNRsXYpOrT3amMHJU2MGJXe1+bOi0PwupYdrv6sLrDZzAUdbcO1hN2vw/h4Ehtt8L08NuGvAU20GRneV+dNTYwa2yGSIam22goUlmMHNFgw2BwTZzdav0FjzCIkxx0xVlUF5AZQVmD/r3s9dfewzayrMVbdrKsxAaqt7rxgIiTaPulrrjprK2vc9UvveR83Xuqtr37saLFazJa/uPRxR5my+4DAIDjHvq9Vmfm51GVSXmweYz1ts5mfZ7Gb4tNcGUEek+ZrSQ+a9Lj1k1lBddtz7lJmfE9uu9mhvthT6qXVQYacBFHZEzj5uj8Gibfm8smgH3+43/8jbbVau6JXCJelJnN85gQjHWdbSUFVmrv58eDsc3glHdpiB6Pg/fo7I2muPG0NUWVz7x7D2D6Kn+oc/x+YwW4UsVvP1x6891OxYzJDwU1rTWpqgEPM4PrRZbTD2Q3NRzUaksNMACjsiZy/DMFi68zAvL9rJ13sKvM8H2ywMah/PkC6tuKZPa+KbYzdXIBiG2fpQL8DU/le+PQyCw0/srqqpMkNPRZEZror2H+uWKy+obaE5rtUmJNpscQlPMKfhh0SbY5k81ce1AB33u6f28ff/+B7fWmOzmy0cpYdqW70OgiuntiWl6thRU2HWWXYUqorrfw9rMITFmS0+waG1nxNsfpY1qDYEOGp/2s3vXVFobi5bUWi2UHlqW5w8brNmm918z7A487uGxta2NB3XcuVxm61yFS5zY9qKomOtN9XlZs2emuNae0LNGiyW2vvmPtZ6VlVirgd1fHgLCoHwRAiPN2uwh5v/OwaHmkely1wzquA7cO0/dQvevWvNNacakcJOAyjsiAjAN98VMHdDDl9k5bP3SJn3+XC7jdt/1oE7f9aeyKa8VYX4V03VsW6l0FizBaylDO6uC6A2e20r3Gl+r5oqMyjWVB3rvvPUmIHKmWF2qzUihZ0GUNgRkeMZhsHuw6V8sS2fOWsPsCXHBUBMWDB3D+nI2Mx2hATbAlyliCjsNIDCjoicisdj8MnmXH7/aRa7D5UC5iyu/mmx9E2LpV9aLL3axBBqV/gR8TeFnQZQ2BGRH1Pj9vDBugO88NkODhSW1ztns1q4pFsSvxzamfQU/TtExF8UdhpAYUdETle128Pmgy7W7D3K2r1HWbP3KLmuY4NxL003Q0+P1tEBrFLk7KCw0wAKOyLyU2TlFvPKFzuZu+Ggd9Hii7q0Ylh6Eud1TCAtPqxp7cYu0kIo7DSAwo6INIYdecW8vGgnHx0XegBSokPI7JjAqJ5OhpyTiNWq4CPSGBR2GkBhR0Qa065DJcz9Nofluw6zLruQKvexdUc6J0Yw4YIOXNW7NfagZrYvl0gTo7DTAAo7IuIr5VVuvtlbwBfbDvH+N/sorqwBICnKwc/Pa8/ovm1oFakFC0XOhMJOAyjsiIg/uCqqeWdVNn9ftoc8l7lCrc1q4WedE7imT2suTXdqCrtIAyjsNIDCjoj4U1WNhw/XH+DtVdl8u6/Q+3y43caQrolkdogns2M8HRLCNbBZ5Aco7DSAwo6IBMruQyV8uO4AH6w/wL6C+uv3JEY6yOwYz7jB7ejbNjZAFYo0XQo7DaCwIyKBZhgGa7MLWbrjMCt2H2ZtdiFVNccGNl+ansSU4V3onBQZwCpFmhaFnQZQ2BGRpqai2s36fYX8Z81+/rN2Px4DrBYY3bcN4wa3Iz7CTmRIMOF2m7q65KylsNMACjsi0pTtzC/muQVZLNicd8I5q8Xcq2twpwSu6pXCkC6JmtIuZw2FnQZQ2BGR5mBd9lH++NkONh0owlVeTY3nxH99R4cGc1lGMpdlOMloHU1MmD0AlYr4h8JOAyjsiEhzYxgGFdUeiiuq2V9YzrwNOfzv24PkF1fWu651TCjpKVF0T4miqzOKc5IiSIsPx6ZVnKUFUNhpAIUdEWkJ3B6DlbuP8N/1B1ix+8gJs7vqOIKsdEqMoKszit5tY+jbNoYuSZEE2dT9Jc2Lwk4DKOyISEtUVF7NthwXmw+62JLjYnteMdvziqmo9pxwbZjdRq82MQxoH0dmh3j6tI0hJFgLHErTprDTAAo7InK28HgM9h0tIyu3mE0HXazLPsr67ELvNhZ17EFW+raNYWC7OFLjwkiODiU5JgRnVAjhjqAAVS9Sn8JOAyjsiMjZzO0x2Jlfwpq9R1m5+wgrdh/h0PfG/hwvJTqE/u3iGNAulv7t4uiSFKmd3CUgFHYaQGFHROQYwzDYdaiUFbuPsHF/ITlFFeTWHt9vAQKIDAmiS1IknZMiOScpgnOSIumUGEFipENrAIlPKew0gMKOiMjpcVVUs2l/Eau/O8o3ewtYs/coZVXuk14bEmylbVwYafHhtIsPo0fraPqlxdI6JlQhSBqFwk4DKOyIiJyZGreH7Xkl7Mgvrh0AXcKOvGKyC8o4yTJAgLnnV7+0WHq2iaFjq3A6tAqnbVy4FkOUBlPYaQCFHRGRxlXt9nDgaDnfHSklu6CM3YdKWZd9lM0HXSddDNFmtZAaG0pqXBhtYkNpE1v3M5R28eHEhdvVGiQnON2/3xpSLyIijS7YZqVdQjjtEsLrPV9R7WbD/iLW7D3KtlwXuw+VsvtQCaVVbr47UsZ3R8pO+n5RIUG0r32/+HAHYXYboXYbYXYb0aHBdEqMoHNiJKF2TZeXE6llB7XsiIgEkmEYHCquZNehUvYfLWP/0XL2Hy3nQGEZ2UfKOFhUcVrvY7VAu/hwujgjaZcQjjMqhKSoEJKiHDijQ0iMDNHK0S2MWnZERKRZsFgsJEaFkBgVAsSfcL68ys3eglK+O1zKnsNlFJVXU15VQ1mVm7JqNwUlVWzPK+ZIaRW7D5ey+3DpST8nyGohKSqE1jGhpMSEEBNmx2qxYLOC1WrBbjMHVHdxRqqVqIVR2BERkSYt1G6jq9Pc2+uHHCquZFuui6zcYvYfLSe3qIK84gryiirIK66kxmNwoLCcA4Un30bjeBYLtI0Lo2OrCFrHhNI6NpSUmFBax4TQxRlFhBZWbFb0v5aIiLQIrSIdtIpsxc86tzrhnNtjdpUdKCznYO3hqqjG7QGPYeD2GFRUu9l9qJSsvGIKSqvYe6SMvScZQ2SzWkhPjqJ/u1gGtIujU2IErvJqjpZVc7SsCld5NQkRDrqnRNE+IVx7jjUBGrODxuyIiEh9h0sqycot5rsjpbXhqIIDheVkHykj13V6Y4jA3HS1qzOSjokRhATbsNusBFktBNmsJETYaZ8QTvuEcFLjwghWKGowTT1vAIUdERE5XQcLy/lm71G++a6Ar/cUcLCwnJgwO7FhwcSE2YkKDSansJytOS5KT7Hg4vfZrBbaxIYSW/v6qJAgokODiQ2zkxjloFWEg1aRDhIiHIQE2wiyWQi2WgmyWQgJtp21A6+bRdj58ssvee6551izZg05OTl88MEHXH311d7z48eP580336z3muHDh/PJJ594HxcUFHDvvffy0UcfYbVaGT16NC+++CIRERGnXYfCjoiINDaPxyC7oIwtOS6+O1JKdY1BjcdDldtDdY1BnquC3YfNgdfl1acXik4myGohOSaE1NhjaxRFhwZ7p+aH2W1EOIKJCas9Qu0tZgHHZjEbq7S0lF69enHbbbdx7bXXnvSaESNG8MYbb3gfOxyOeufHjBlDTk4OCxcupLq6mp///OdMmDCB2bNn+7R2ERGRH2K1Wk661tD3eTwGecUV7Csop6i8Gld5NUW1x9GyKg4VV5pHSSWHiyvNsOQ+1k5R4zHYV1DOvoIfH3hdJ8IRRKjdhiPIij3IiiPIRrjdRlq8uaK1ubJ1BAkRDuxBVuw2K8E2S7Nd2DGgYWfkyJGMHDnyB69xOBw4nc6Tntu6dSuffPIJq1evpn///gC8/PLLXHbZZfz+978nJSWl0WsWERFpTFarheToUJKjQ0/7NYZhUOMxqHEbFJZXsf9oOfsKythXYK5PVFJZOzW/yk15lZuSyhoKy6ooKq/GY0BJZQ0lJ9nU9Zu9R0/5mRYLhAbbSIoKITk6hORocwq/3Wb1hjNXRTVlVW5aRTpIiwunXUKYd3+02LDggIWlJj8ba/HixSQmJhIbG8vFF1/M//t//4/4eHMdhhUrVhATE+MNOgDDhg3DarWyatUqrrnmmpO+Z2VlJZWVld7HLpfLt19CRESkEVksFoJtFoJtEGo3g9KAdnE/+jqPx8BVYc4cK69yU+X2UFntprLGQ1F5NXsOmyta7z5cyu5DpfUCkWFAWZWbPYdL2XOKtYx+yAd3D6ZP29gGv64xNOmwM2LECK699lrat2/Prl27eOSRRxg5ciQrVqzAZrORm5tLYmJivdcEBQURFxdHbm7uKd93+vTpPPnkk74uX0REpEmxWi3EhNmJCbOf1vVuj0FVjYeqGg+VbjdllW5yXRXkFJkz1A4WllPjNogOCyY6NJio0GBCg23kFpWbU/cLyrwz2NLif7g7z5eadNi58cYbvb9nZGTQs2dPOnbsyOLFixk6dOgZv+/UqVN54IEHvI9dLhepqak/qVYREZGWxma1EFq7DxkEQyQ/OgbpZCqq3TgCOCi6WQ3H7tChAwkJCezcuRMAp9NJfn5+vWtqamooKCg45TgfMMcBRUVF1TtERETEN0KCbQEd3Nysws7+/fs5cuQIycnJAGRmZlJYWMiaNWu81yxatAiPx8OgQYMCVaaIiIg0IQHtxiopKfG20gDs2bOH9evXExcXR1xcHE8++SSjR4/G6XSya9cuHnroITp16sTw4cMB6NatGyNGjODOO+/ktddeo7q6mnvuuYcbb7xRM7FEREQECPCigosXL+aiiy464flx48bx6quvcvXVV7Nu3ToKCwtJSUnh0ksvZdq0aSQlJXmvLSgo4J577qm3qOBLL72kRQVFRERauGaxgnJTobAjIiLS/Jzu3+9mNWZHREREpKEUdkRERKRFU9gRERGRFk1hR0RERFo0hR0RERFp0RR2REREpEVT2BEREZEWTWFHREREWjSFHREREWnRAro3VlNRt4i0y+UKcCUiIiJyuur+bv/YZhAKO0BxcTEAqampAa5EREREGqq4uJjo6OhTntfeWIDH4+HgwYNERkZisVga7X1dLhepqans27dPe275mO61/+he+4/utX/pfvtPY91rwzAoLi4mJSUFq/XUI3PUsgNYrVbatGnjs/ePiorS/3H8RPfaf3Sv/Uf32r90v/2nMe71D7Xo1NEAZREREWnRFHZERESkRVPY8SGHw8Fvf/tbHA5HoEtp8XSv/Uf32n90r/1L99t//H2vNUBZREREWjS17IiIiEiLprAjIiIiLZrCjoiIiLRoCjsiIiLSoins+NDMmTNp164dISEhDBo0iK+//jrQJTV706dPZ8CAAURGRpKYmMjVV19NVlZWvWsqKiqYNGkS8fHxREREMHr0aPLy8gJUccswY8YMLBYL999/v/c53efGdeDAAW655Rbi4+MJDQ0lIyODb775xnveMAwef/xxkpOTCQ0NZdiwYezYsSOAFTdPbreb3/zmN7Rv357Q0FA6duzItGnT6u2tpHt9Zr788kuuuOIKUlJSsFgsfPjhh/XOn859LSgoYMyYMURFRRETE8Ptt99OSUnJTy/OEJ949913Dbvdbvz97383Nm/ebNx5551GTEyMkZeXF+jSmrXhw4cbb7zxhrFp0yZj/fr1xmWXXWa0bdvWKCkp8V5z1113Gampqcbnn39ufPPNN8a5555rDB48OIBVN29ff/210a5dO6Nnz57Gfffd531e97nxFBQUGGlpacb48eONVatWGbt37zYWLFhg7Ny503vNjBkzjOjoaOPDDz80vv32W+PKK6802rdvb5SXlwew8ubnd7/7nREfH2/MnTvX2LNnj/H+++8bERERxosvvui9Rvf6zMybN8949NFHjTlz5hiA8cEHH9Q7fzr3dcSIEUavXr2MlStXGl999ZXRqVMn46abbvrJtSns+MjAgQONSZMmeR+73W4jJSXFmD59egCranny8/MNwFiyZIlhGIZRWFhoBAcHG++//773mq1btxqAsWLFikCV2WwVFxcbnTt3NhYuXGhceOGF3rCj+9y4Hn74YeP8888/5XmPx2M4nU7jueee8z5XWFhoOBwO45133vFHiS3GqFGjjNtuu63ec9dee60xZswYwzB0rxvL98PO6dzXLVu2GICxevVq7zXz5883LBaLceDAgZ9Uj7qxfKCqqoo1a9YwbNgw73NWq5Vhw4axYsWKAFbW8hQVFQEQFxcHwJo1a6iurq5377t27Urbtm1178/ApEmTGDVqVL37CbrPje1///sf/fv35//+7/9ITEykT58+vP76697ze/bsITc3t979jo6OZtCgQbrfDTR48GA+//xztm/fDsC3337L0qVLGTlyJKB77Sunc19XrFhBTEwM/fv3914zbNgwrFYrq1at+kmfr41AfeDw4cO43W6SkpLqPZ+UlMS2bdsCVFXL4/F4uP/++znvvPPo0aMHALm5udjtdmJiYupdm5SURG5ubgCqbL7effdd1q5dy+rVq084p/vcuHbv3s2rr77KAw88wCOPPMLq1av55S9/id1uZ9y4cd57erJ/p+h+N8yvf/1rXC4XXbt2xWaz4Xa7+d3vfseYMWMAdK995HTua25uLomJifXOBwUFERcX95PvvcKONFuTJk1i06ZNLF26NNCltDj79u3jvvvuY+HChYSEhAS6nBbP4/HQv39/nn76aQD69OnDpk2beO211xg3blyAq2tZ3nvvPd5++21mz55N9+7dWb9+Pffffz8pKSm61y2YurF8ICEhAZvNdsLMlLy8PJxOZ4Cqalnuuece5s6dyxdffEGbNm28zzudTqqqqigsLKx3ve59w6xZs4b8/Hz69u1LUFAQQUFBLFmyhJdeeomgoCCSkpJ0nxtRcnIy6enp9Z7r1q0b2dnZAN57qn+n/HRTpkzh17/+NTfeeCMZGRnceuutTJ48menTpwO6175yOvfV6XSSn59f73xNTQ0FBQU/+d4r7PiA3W6nX79+fP75597nPB4Pn3/+OZmZmQGsrPkzDIN77rmHDz74gEWLFtG+fft65/v160dwcHC9e5+VlUV2drbufQMMHTqUjRs3sn79eu/Rv39/xowZ4/1d97nxnHfeeScsobB9+3bS0tIAaN++PU6ns979drlcrFq1Sve7gcrKyrBa6//ps9lseDweQPfaV07nvmZmZlJYWMiaNWu81yxatAiPx8OgQYN+WgE/aXiznNK7775rOBwOY9asWcaWLVuMCRMmGDExMUZubm6gS2vWJk6caERHRxuLFy82cnJyvEdZWZn3mrvuusto27atsWjRIuObb74xMjMzjczMzABW3TIcPxvLMHSfG9PXX39tBAUFGb/73e+MHTt2GG+//bYRFhZmvPXWW95rZsyYYcTExBj//e9/jQ0bNhhXXXWVpkOfgXHjxhmtW7f2Tj2fM2eOkZCQYDz00EPea3Svz0xxcbGxbt06Y926dQZgPP/888a6deuMvXv3GoZxevd1xIgRRp8+fYxVq1YZS5cuNTp37qyp503dyy+/bLRt29aw2+3GwIEDjZUrVwa6pGYPOOnxxhtveK8pLy837r77biM2NtYICwszrrnmGiMnJydwRbcQ3w87us+N66OPPjJ69OhhOBwOo2vXrsZf/vKXeuc9Ho/xm9/8xkhKSjIcDocxdOhQIysrK0DVNl8ul8u47777jLZt2xohISFGhw4djEcffdSorKz0XqN7fWa++OKLk/77edy4cYZhnN59PXLkiHHTTTcZERERRlRUlPHzn//cKC4u/sm1WQzjuGUjRURERFoYjdkRERGRFk1hR0RERFo0hR0RERFp0RR2REREpEVT2BEREZEWTWFHREREWjSFHREREWnRFHZERESkRVPYERH5nsWLF2OxWE7Y6FREmieFHREREWnRFHZERESkRVPYEZEmx+PxMH36dNq3b09oaCi9evXi3//+N3Csi+njjz+mZ8+ehISEcO6557Jp06Z67/Gf//yH7t2743A4aNeuHX/4wx/qna+srOThhx8mNTUVh8NBp06d+Nvf/lbvmjVr1tC/f3/CwsIYPHgwWVlZvv3iIuITCjsi0uRMnz6df/zjH7z22mts3ryZyZMnc8stt7BkyRLvNVOmTOEPf/gDq1evplWrVlxxxRVUV1cDZki5/vrrufHGG9m4cSNPPPEEv/nNb5g1a5b39WPHjuWdd97hpZdeYuvWrfz5z38mIiKiXh2PPvoof/jDH/jmm28ICgritttu88v3F5HGpV3PRaRJqaysJC4ujs8++4zMzEzv83fccQdlZWVMmDCBiy66iHfffZcbbrgBgIKCAtq0acOsWbO4/vrrGTNmDIcOHeLTTz/1vv6hhx7i448/ZvPmzWzfvp0uXbqwcOFChg0bdkINixcv5qKLLuKzzz5j6NChAMybN49Ro0ZRXl5OSEiIj++CiDQmteyISJOyc+dOysrKuOSSS4iIiPAe//jHP9i1a5f3uuODUFxcHF26dGHr1q0AbN26lfPOO6/e+5533nns2LEDt9vN+vXrsdlsXHjhhT9YS8+ePb2/JycnA5Cfn/+Tv6OI+FdQoAsQETleSUkJAB9//DGtW7eud87hcNQLPGcqNDT0tK4LDg72/m6xWABzPJGINC9q2RGRJiU9PR2Hw0F2djadOnWqd6SmpnqvW7lypff3o0ePsn37drp16wZAt27dWLZsWb33XbZsGeeccw42m42MjAw8Hk+9MUAi0nKpZUdEmpTIyEgefPBBJk+ejMfj4fzzz6eoqIhly5YRFRVFWloaAE899RTx8fEkJSXx6KOPkpCQwNVXXw3Ar371KwYMGMC0adO44YYbWLFiBa+88gp/+tOfAGjXrh3jxo3jtttu46WXXqJXr17s3buX/Px8rr/++kB9dRHxEYUdEWlypk2bRqtWrZg+fTq7d+8mJiaGvn378sgjj3i7kWbMmMF9993Hjh076N27Nx999BF2ux2Avn378t577/H4448zbdo0kpOTeeqppxg/frz3M1599VUeeeQR7r77bo4cOULbtm155JFHAvF1RcTHNBtLRJqVuplSR48eJSYmJtDliEgzoDE7IiIi0qIp7IiIiEiLpm4sERERadHUsiMiIiItmsKOiIiItGgKOyIiItKiKeyIiIhIi6awIyIiIi2awo6IiIi0aAo7IiIi0qIp7IiIiEiL9v8BmsD5aOl2dD4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history, label = 'Train')\n",
    "plt.plot(val_history, label = 'Val')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.savefig(os.path.join('SSL/figures/geo_pretrain', f'SSL_learning_curve_{num_epoch}_{norm}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not really learning - why? maybe compare to MOFormer and see how much their loss decreased by.\n",
    "#edit: issue fixed, initially set learning rate -> 0.0051 but it was too high (must have gotten stuck in a local minima somewhere) - it is learning now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
