{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSL pipeline (Barlow-Twin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "#from keras.layers.merge import add\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, Tensor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sartaaj/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CoRE_2019.MOFormer_modded.transformer import Transformer, TransformerRegressor\n",
    "from CoRE_2019.MOFormer_modded.dataset_modded import MOF_ID_Dataset\n",
    "from CoRE_2019.MOFormer_modded.tokenizer.mof_tokenizer import MOFTokenizer\n",
    "import csv\n",
    "import yaml\n",
    "from CoRE_2019.MOFormer_modded.model.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from CoRE_2019.CGCNN.extract import extractFeaturesCGCNN\n",
    "from CoRE_2019.CGCNN.extract import collate_pool_mod\n",
    "from CoRE_2019.CGCNN.cgcnn_pretrain import CrystalGraphConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MOFTokenizer(\"CoRE_2019/MOFormer_modded/tokenizer/vocab_full.txt\")\n",
    "config = yaml.load(open(\"CoRE_2019/MOFormer_modded/config_ft_transformer.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "config['dataloader']['randomSeed'] = 0\n",
    "\n",
    "if torch.cuda.is_available() and config['gpu'] != 'cpu':\n",
    "    device = config['gpu']\n",
    "    torch.cuda.set_device(device)\n",
    "    config['cuda'] = True\n",
    "\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    config['cuda'] = False\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoRE_2019.MOFormer_modded.transformer import PositionalEncoding\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "\n",
    "batch_size = 64\n",
    "class TransformerXRD(nn.Module):\n",
    "    def __init__(self, input_features=8192, seq_length=batch_size, transformer_heads=8, transformer_ff_dim=512, mlp_hidden_dim=256):\n",
    "        super(TransformerXRD, self).__init__()\n",
    "        \n",
    "        # Project input features to sequence length dimension\n",
    "        self.input_proj = nn.Linear(input_features, seq_length)\n",
    "        \n",
    "        # Define a single Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=seq_length, nhead=transformer_heads, dim_feedforward=transformer_ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        \n",
    "        # MLP for regression output\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(seq_length, mlp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_dim, 1)  # Output layer for regression\n",
    "        )\n",
    "        self.mlp_manip = nn.Sequential(\n",
    "            nn.Linear(seq_length, mlp_hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project input features to sequence length dimension\n",
    "        x_proj = self.input_proj(x)\n",
    "        x_proj = x_proj.transpose(0, 1)\n",
    "        \n",
    "        # Pass through the Transformer encoder\n",
    "        transformer_output = self.transformer_encoder(x_proj)\n",
    "        \n",
    "        # Revert to the original format (N, S) for the MLP\n",
    "        transformer_output = transformer_output.transpose(0, 1)\n",
    "        #print(\"Transformer output shape : {}\".format(transformer_output.shape))\n",
    "        \n",
    "        # Pass through the MLP\n",
    "        #output = self.mlp(transformer_output)\n",
    "        \n",
    "        # Squeeze the output to remove the extra dimension if the output dimension is 1 -> else, consider alternative for multi-output regression tasks; maybe make conditional?\n",
    "        return transformer_output\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.token_encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        # initrange = 0.1\n",
    "        # self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        nn.init.xavier_normal_(self.token_encoder.weight)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.token_encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output[:, 0:1, :] #this was added in by me\n",
    "\n",
    "        return output.squeeze(dim = 1) #this was added in by me\n",
    "        #return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_SMILES = Transformer(**config['Transformer'])\n",
    "transformer_XRD = TransformerXRD()\n",
    "\n",
    "class UnifiedTransformer(nn.Module):\n",
    "    def __init__(self, config, input_features=8192, seq_length=batch_size, transformer_heads=8, transformer_ff_dim=512, mlp_hidden_dim=256):\n",
    "        super(UnifiedTransformer, self).__init__()\n",
    "        \n",
    "        # Initialize Transformer1 with its parameters\n",
    "        self.transformer1 = Transformer(**config['Transformer'])\n",
    "        \n",
    "        # Initialize Transformer2 components\n",
    "        self.transformer2 = TransformerXRD(input_features, seq_length, transformer_heads, transformer_ff_dim, mlp_hidden_dim)\n",
    "\n",
    "        #projector\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(576, mlp_hidden_dim), #used to be mlp_hidden_dim here instead of 576 (output size)\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(mlp_hidden_dim, 512) #used to be mlp_hidden_dim here instead of 576 (input size)\n",
    "        )\n",
    "                \n",
    "    def forward(self, xrd, smiles):\n",
    "        transformer1_output = self.transformer1(smiles) #gets output from SMILES transformer -> shape of (batchSize, 512, 512)\n",
    "        transformer2_output = self.transformer2(xrd) #gets output from XRD transformer -> shape of (batchSize, seq_len)\n",
    "\n",
    "        # Now, concatenate tensor1 and the corrected pooled_tensor2 along the second dimension\n",
    "        concatenated_tensor_corrected = torch.cat((transformer1_output, transformer2_output), dim=1)\n",
    "        output = self.proj(concatenated_tensor_corrected)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CoRE_2019/CGCNN/ssl_ds_graph.pickle', 'rb') as handle:\n",
    "    ssl_ds_graph = pickle.load(handle)\n",
    "\n",
    "with open('CoRE_2019/CGCNN/ssl_xrd.pickle', 'rb') as handle:\n",
    "    ssl_xrd = pickle.load(handle)\n",
    "\n",
    "with open('CoRE_2019/CGCNN/ssl_smiles.pickle', 'rb') as handle:\n",
    "    ssl_smiles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full pretraining set size is 133\n"
     ]
    }
   ],
   "source": [
    "data_size = len(ssl_xrd) #should give 8.5k entries for CoRE-2019\n",
    "print(f'Full pretraining set size is {data_size}')\n",
    "split_ratio = 0.95 #train set %\n",
    "train_size = int(split_ratio * data_size)\n",
    "\n",
    "ssl_xrd_train, ssl_smiles_train, ssl_graph_train = ssl_xrd[:train_size], ssl_smiles[:train_size], ssl_ds_graph[:train_size]\n",
    "ssl_xrd_val, ssl_smiles_val, ssl_graph_val = ssl_xrd[train_size-1::], ssl_smiles[train_size-1::], ssl_ds_graph[train_size-1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model = UnifiedTransformer(config=config).to(device)\n",
    "\n",
    "orig_atom_fea_len, nbr_fea_len = extractFeaturesCGCNN('CoRE_2019/CGCNN/00958972.2016.1253069_1472494_clean.cif').featureLengths()\n",
    "\n",
    "config_crystal = yaml.load(open(\"CoRE_2019/CGCNN/config_ft_cgcnn.yaml\", \"r\"), Loader=yaml.FullLoader) #configurations for CGCNN\n",
    "\n",
    "config_crystal['model']['orig_atom_fea_len'] = orig_atom_fea_len\n",
    "config_crystal['model']['nbr_fea_len'] = nbr_fea_len\n",
    "\n",
    "model_g = CrystalGraphConvNet(**config_crystal['model']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL.barlow_twins import BarlowTwinsLoss\n",
    "\n",
    "loss = BarlowTwinsLoss(device = device, batch_size = 64, embed_size = 512, lambd = 0.0051) #same parameters as in moformer\n",
    "\n",
    "optimizer_g = optim.Adam(model_g.parameters(), lr = 0.00005)\n",
    "optimizer_t = optim.Adam(model.parameters(), lr = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Ensembled Loss : 391.8476298498729, Val. Ensembled Loss : 296.6166763305664\n",
      "###############################\n",
      "Epoch : 2\n",
      "Ensembled Loss : 269.62337990412635, Val. Ensembled Loss : 236.9739933013916\n",
      "###############################\n",
      "Epoch : 3\n",
      "Ensembled Loss : 215.10306294759116, Val. Ensembled Loss : 197.2298812866211\n",
      "###############################\n",
      "Epoch : 4\n",
      "Ensembled Loss : 187.37942165798611, Val. Ensembled Loss : 176.4807014465332\n",
      "###############################\n",
      "Epoch : 5\n",
      "Ensembled Loss : 169.45048280746218, Val. Ensembled Loss : 160.79550552368164\n",
      "###############################\n",
      "Epoch : 6\n",
      "Ensembled Loss : 152.8185545906188, Val. Ensembled Loss : 147.6320915222168\n",
      "###############################\n",
      "Epoch : 7\n",
      "Ensembled Loss : 139.29761008610802, Val. Ensembled Loss : 134.2743101119995\n",
      "###############################\n",
      "Epoch : 8\n",
      "Ensembled Loss : 127.59053493681408, Val. Ensembled Loss : 123.25258541107178\n",
      "###############################\n",
      "Epoch : 9\n",
      "Ensembled Loss : 119.38490440731957, Val. Ensembled Loss : 114.26038074493408\n",
      "###############################\n",
      "Epoch : 10\n",
      "Ensembled Loss : 111.25466694907537, Val. Ensembled Loss : 108.55762767791748\n",
      "###############################\n",
      "Epoch : 11\n",
      "Ensembled Loss : 106.24408316233801, Val. Ensembled Loss : 104.53821659088135\n",
      "###############################\n",
      "Epoch : 12\n",
      "Ensembled Loss : 102.75160695636083, Val. Ensembled Loss : 103.05322456359863\n",
      "###############################\n",
      "Epoch : 13\n",
      "Ensembled Loss : 100.45406014578683, Val. Ensembled Loss : 101.51163673400879\n",
      "###############################\n",
      "Epoch : 14\n",
      "Ensembled Loss : 98.15743618919736, Val. Ensembled Loss : 99.46646881103516\n",
      "###############################\n",
      "Epoch : 15\n",
      "Ensembled Loss : 94.88026125468905, Val. Ensembled Loss : 95.95861721038818\n",
      "###############################\n",
      "Epoch : 16\n",
      "Ensembled Loss : 91.76857684907459, Val. Ensembled Loss : 93.91898155212402\n",
      "###############################\n",
      "Epoch : 17\n",
      "Ensembled Loss : 89.8912814912342, Val. Ensembled Loss : 92.1096830368042\n",
      "###############################\n",
      "Epoch : 18\n",
      "Ensembled Loss : 87.89088688199482, Val. Ensembled Loss : 89.95716953277588\n",
      "###############################\n",
      "Epoch : 19\n",
      "Ensembled Loss : 85.05839211600167, Val. Ensembled Loss : 87.70600509643555\n",
      "###############################\n",
      "Epoch : 20\n",
      "Ensembled Loss : 82.44607658991738, Val. Ensembled Loss : 85.75446033477783\n",
      "###############################\n",
      "Epoch : 21\n",
      "Ensembled Loss : 80.33218928745815, Val. Ensembled Loss : 84.37065982818604\n",
      "###############################\n",
      "Epoch : 22\n",
      "Ensembled Loss : 79.05646623883929, Val. Ensembled Loss : 83.663893699646\n",
      "###############################\n",
      "Epoch : 23\n",
      "Ensembled Loss : 77.5928475516183, Val. Ensembled Loss : 82.31607246398926\n",
      "###############################\n",
      "Epoch : 24\n",
      "Ensembled Loss : 75.60092211526538, Val. Ensembled Loss : 80.21243095397949\n",
      "###############################\n",
      "Epoch : 25\n",
      "Ensembled Loss : 74.12726792835053, Val. Ensembled Loss : 79.20213031768799\n",
      "###############################\n",
      "Epoch : 26\n",
      "Ensembled Loss : 72.93607675461541, Val. Ensembled Loss : 78.0142011642456\n",
      "###############################\n",
      "Epoch : 27\n",
      "Ensembled Loss : 71.68908146449498, Val. Ensembled Loss : 76.94868087768555\n",
      "###############################\n",
      "Epoch : 28\n",
      "Ensembled Loss : 70.59685516357422, Val. Ensembled Loss : 75.75624179840088\n",
      "###############################\n",
      "Epoch : 29\n",
      "Ensembled Loss : 69.43928975907583, Val. Ensembled Loss : 74.59887313842773\n",
      "###############################\n",
      "Epoch : 30\n",
      "Ensembled Loss : 68.47103851560563, Val. Ensembled Loss : 73.90218448638916\n",
      "###############################\n",
      "Epoch : 31\n",
      "Ensembled Loss : 67.7774266439771, Val. Ensembled Loss : 73.36998653411865\n",
      "###############################\n",
      "Epoch : 32\n",
      "Ensembled Loss : 67.01115084451342, Val. Ensembled Loss : 73.03485202789307\n",
      "###############################\n",
      "Epoch : 33\n",
      "Ensembled Loss : 66.08270626976376, Val. Ensembled Loss : 72.25445652008057\n",
      "###############################\n",
      "Epoch : 34\n",
      "Ensembled Loss : 65.24243472871326, Val. Ensembled Loss : 71.55171298980713\n",
      "###############################\n",
      "Epoch : 35\n",
      "Ensembled Loss : 64.51204793415373, Val. Ensembled Loss : 70.94881629943848\n",
      "###############################\n",
      "Epoch : 36\n",
      "Ensembled Loss : 63.68023951091464, Val. Ensembled Loss : 70.03426742553711\n",
      "###############################\n",
      "Epoch : 37\n",
      "Ensembled Loss : 62.90468055482895, Val. Ensembled Loss : 69.3964114189148\n",
      "###############################\n",
      "Epoch : 38\n",
      "Ensembled Loss : 62.05660205417209, Val. Ensembled Loss : 68.56996726989746\n",
      "###############################\n",
      "Epoch : 39\n",
      "Ensembled Loss : 61.35403775411939, Val. Ensembled Loss : 67.9108099937439\n",
      "###############################\n",
      "Epoch : 40\n",
      "Ensembled Loss : 60.78163074311756, Val. Ensembled Loss : 67.61483192443848\n",
      "###############################\n",
      "Epoch : 41\n",
      "Ensembled Loss : 60.24657873123411, Val. Ensembled Loss : 67.37079668045044\n",
      "###############################\n",
      "Epoch : 42\n",
      "Ensembled Loss : 59.71084679497613, Val. Ensembled Loss : 66.89810943603516\n",
      "###############################\n",
      "Epoch : 43\n",
      "Ensembled Loss : 59.27796572730655, Val. Ensembled Loss : 66.6470136642456\n",
      "###############################\n",
      "Epoch : 44\n",
      "Ensembled Loss : 58.700210238259935, Val. Ensembled Loss : 66.23239707946777\n",
      "###############################\n",
      "Epoch : 45\n",
      "Ensembled Loss : 58.2344115121024, Val. Ensembled Loss : 65.7223768234253\n",
      "###############################\n",
      "Epoch : 46\n",
      "Ensembled Loss : 57.7266780005561, Val. Ensembled Loss : 65.49884271621704\n",
      "###############################\n",
      "Epoch : 47\n",
      "Ensembled Loss : 57.28861763363793, Val. Ensembled Loss : 65.16495084762573\n",
      "###############################\n",
      "Epoch : 48\n",
      "Ensembled Loss : 56.95296908181811, Val. Ensembled Loss : 65.04388189315796\n",
      "###############################\n",
      "Epoch : 49\n",
      "Ensembled Loss : 56.57142996409583, Val. Ensembled Loss : 64.80655193328857\n",
      "###############################\n",
      "Epoch : 50\n",
      "Ensembled Loss : 56.190499805268786, Val. Ensembled Loss : 64.46348714828491\n",
      "###############################\n",
      "Epoch : 51\n",
      "Ensembled Loss : 55.836443643721324, Val. Ensembled Loss : 64.06735324859619\n",
      "###############################\n",
      "Epoch : 52\n",
      "Ensembled Loss : 55.40647294786241, Val. Ensembled Loss : 63.962018966674805\n",
      "###############################\n",
      "Epoch : 53\n",
      "Ensembled Loss : 54.87984006367032, Val. Ensembled Loss : 63.36478805541992\n",
      "###############################\n",
      "Epoch : 54\n",
      "Ensembled Loss : 54.50117604694669, Val. Ensembled Loss : 62.97189664840698\n",
      "###############################\n",
      "Epoch : 55\n",
      "Ensembled Loss : 54.07636036948552, Val. Ensembled Loss : 62.44522190093994\n",
      "###############################\n",
      "Epoch : 56\n",
      "Ensembled Loss : 53.68008180648562, Val. Ensembled Loss : 62.14626741409302\n",
      "###############################\n",
      "Epoch : 57\n",
      "Ensembled Loss : 53.24735599093967, Val. Ensembled Loss : 61.66122007369995\n",
      "###############################\n",
      "Epoch : 58\n",
      "Ensembled Loss : 52.83385470556834, Val. Ensembled Loss : 61.13441705703735\n",
      "###############################\n",
      "Epoch : 59\n",
      "Ensembled Loss : 52.49732813759456, Val. Ensembled Loss : 60.76378583908081\n",
      "###############################\n",
      "Epoch : 60\n",
      "Ensembled Loss : 52.14329695323157, Val. Ensembled Loss : 60.48377084732056\n",
      "###############################\n",
      "Epoch : 61\n",
      "Ensembled Loss : 51.809320631481356, Val. Ensembled Loss : 60.2341423034668\n",
      "###############################\n",
      "Epoch : 62\n",
      "Ensembled Loss : 51.33008030482701, Val. Ensembled Loss : 59.898560523986816\n",
      "###############################\n",
      "Epoch : 63\n",
      "Ensembled Loss : 50.89606403169178, Val. Ensembled Loss : 59.983473777770996\n",
      "###############################\n",
      "Epoch : 64\n",
      "Ensembled Loss : 50.43923792763362, Val. Ensembled Loss : 59.38670301437378\n",
      "###############################\n",
      "Epoch : 65\n",
      "Ensembled Loss : 49.97429448082333, Val. Ensembled Loss : 59.07376194000244\n",
      "###############################\n",
      "Epoch : 66\n",
      "Ensembled Loss : 49.55940855117071, Val. Ensembled Loss : 59.01745891571045\n",
      "###############################\n",
      "Epoch : 67\n",
      "Ensembled Loss : 49.264773959205264, Val. Ensembled Loss : 58.54587268829346\n",
      "###############################\n",
      "Epoch : 68\n",
      "Ensembled Loss : 48.920984025985476, Val. Ensembled Loss : 58.541696548461914\n",
      "###############################\n",
      "Epoch : 69\n",
      "Ensembled Loss : 48.56779558696444, Val. Ensembled Loss : 58.122334003448486\n",
      "###############################\n",
      "Epoch : 70\n",
      "Ensembled Loss : 48.332659948439826, Val. Ensembled Loss : 58.29430437088013\n",
      "###############################\n",
      "Epoch : 71\n",
      "Ensembled Loss : 48.06755541241358, Val. Ensembled Loss : 57.90955877304077\n",
      "###############################\n",
      "Epoch : 72\n",
      "Ensembled Loss : 47.83470108395531, Val. Ensembled Loss : 57.815815925598145\n",
      "###############################\n",
      "Epoch : 73\n",
      "Ensembled Loss : 47.573990836976066, Val. Ensembled Loss : 57.58794689178467\n",
      "###############################\n",
      "Epoch : 74\n",
      "Ensembled Loss : 47.35216537354484, Val. Ensembled Loss : 57.52894687652588\n",
      "###############################\n",
      "Epoch : 75\n",
      "Ensembled Loss : 47.11527479262579, Val. Ensembled Loss : 57.39863395690918\n",
      "###############################\n",
      "Epoch : 76\n",
      "Ensembled Loss : 46.89753486996605, Val. Ensembled Loss : 56.89526033401489\n",
      "###############################\n",
      "Epoch : 77\n",
      "Ensembled Loss : 46.628371072193936, Val. Ensembled Loss : 56.99623918533325\n",
      "###############################\n",
      "Epoch : 78\n",
      "Ensembled Loss : 46.37684649512882, Val. Ensembled Loss : 56.724053382873535\n",
      "###############################\n",
      "Epoch : 79\n",
      "Ensembled Loss : 46.19468174283467, Val. Ensembled Loss : 56.76629400253296\n",
      "###############################\n",
      "Epoch : 80\n",
      "Ensembled Loss : 45.95023809160505, Val. Ensembled Loss : 56.40798044204712\n",
      "###############################\n",
      "Epoch : 81\n",
      "Ensembled Loss : 45.72581454685756, Val. Ensembled Loss : 56.28589725494385\n",
      "###############################\n",
      "Epoch : 82\n",
      "Ensembled Loss : 45.581669792296395, Val. Ensembled Loss : 56.10606288909912\n",
      "###############################\n",
      "Epoch : 83\n",
      "Ensembled Loss : 45.37214645506844, Val. Ensembled Loss : 56.400782108306885\n",
      "###############################\n",
      "Epoch : 84\n",
      "Ensembled Loss : 45.24110503423782, Val. Ensembled Loss : 56.129220485687256\n",
      "###############################\n",
      "Epoch : 85\n",
      "Ensembled Loss : 45.09197389511835, Val. Ensembled Loss : 56.09752941131592\n",
      "###############################\n",
      "Epoch : 86\n",
      "Ensembled Loss : 44.93836193992978, Val. Ensembled Loss : 56.43912982940674\n",
      "###############################\n",
      "Epoch : 87\n",
      "Ensembled Loss : 44.72268803914388, Val. Ensembled Loss : 56.29246234893799\n",
      "###############################\n",
      "Epoch : 88\n",
      "Ensembled Loss : 44.528048924037385, Val. Ensembled Loss : 56.12853717803955\n",
      "###############################\n",
      "Epoch : 89\n",
      "Ensembled Loss : 44.2924937293643, Val. Ensembled Loss : 55.701329708099365\n",
      "###############################\n",
      "Epoch : 90\n",
      "Ensembled Loss : 43.926090815710644, Val. Ensembled Loss : 55.617526054382324\n",
      "###############################\n",
      "Epoch : 91\n",
      "Ensembled Loss : 43.738891086881125, Val. Ensembled Loss : 55.55381774902344\n",
      "###############################\n",
      "Epoch : 92\n",
      "Ensembled Loss : 43.47917378137982, Val. Ensembled Loss : 55.52644109725952\n",
      "###############################\n",
      "Epoch : 93\n",
      "Ensembled Loss : 43.22723755003914, Val. Ensembled Loss : 55.55559825897217\n",
      "###############################\n",
      "Epoch : 94\n",
      "Ensembled Loss : 43.06336224268353, Val. Ensembled Loss : 55.36320686340332\n",
      "###############################\n",
      "Epoch : 95\n",
      "Ensembled Loss : 42.86922182355608, Val. Ensembled Loss : 55.72285032272339\n",
      "###############################\n",
      "Epoch : 96\n",
      "Ensembled Loss : 42.704448033892916, Val. Ensembled Loss : 55.49316453933716\n",
      "###############################\n",
      "Epoch : 97\n",
      "Ensembled Loss : 42.522339624071876, Val. Ensembled Loss : 55.483245849609375\n",
      "###############################\n",
      "Epoch : 98\n",
      "Ensembled Loss : 42.34829182094998, Val. Ensembled Loss : 55.39115238189697\n",
      "###############################\n",
      "Epoch : 99\n",
      "Ensembled Loss : 42.189562267727325, Val. Ensembled Loss : 55.121832847595215\n",
      "###############################\n",
      "Epoch : 100\n",
      "Ensembled Loss : 42.00116333128914, Val. Ensembled Loss : 55.187734603881836\n",
      "###############################\n"
     ]
    }
   ],
   "source": [
    "#now, test for 100 epoch?\n",
    "\n",
    "num_epoch = 100\n",
    "loss_history = []\n",
    "val_history = []\n",
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "norm = False #should embeddings be normalized? in crystal-twin, they don't but for barlow-twin, it's in the algorithm\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model_g.train()\n",
    "    model.train()\n",
    "\n",
    "    print(f'Epoch : {epoch + 1}')\n",
    "    loss_ensemble = []\n",
    "    for bn, (graph, xrd, smiles) in enumerate(zip(ssl_graph_train, ssl_xrd_train, ssl_smiles_train)):\n",
    "        input_graph_1 = (Variable(graph[0]).to(device),\n",
    "                        Variable(graph[1]).to(device),\n",
    "                        Variable(graph[2]).to(device),\n",
    "                        [crys_idx.to(device) for crys_idx in graph[3]])\n",
    "        \n",
    "        xrd = torch.tensor(xrd, dtype = torch.float).to(device)\n",
    "        smiles = torch.from_numpy(smiles).to(device)\n",
    "        \n",
    "        z_a = model_g(*input_graph_1) #embedding from cgcnn\n",
    "        z_b = model(xrd, smiles) #embedding from concat. model\n",
    "\n",
    "        if norm == True:\n",
    "            z_a_norm = (z_a - torch.mean(z_a, axis = 0))/torch.std(z_a, axis = 0)\n",
    "            z_b_norm = (z_b - torch.mean(z_b, axis = 0))/torch.std(z_b, axis = 0)\n",
    "        \n",
    "        else:\n",
    "            z_a_norm = z_a\n",
    "            z_b_norm = z_b\n",
    "\n",
    "        loss_calc = loss(z_a_norm, z_b_norm)\n",
    "        loss_ensemble.append(loss_calc.item())\n",
    "\n",
    "        optimizer_g.zero_grad()\n",
    "        optimizer_t.zero_grad()\n",
    "\n",
    "        loss_calc.backward()\n",
    "\n",
    "        optimizer_g.step()\n",
    "        optimizer_t.step()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    val_ensemble = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model_g.eval()\n",
    "        for bn, (graph, xrd, smiles) in enumerate(zip(ssl_graph_val, ssl_xrd_val, ssl_smiles_val)):\n",
    "            input_graph_1 = (Variable(graph[0]).to(device),\n",
    "                            Variable(graph[1]).to(device),\n",
    "                            Variable(graph[2]).to(device),\n",
    "                            [crys_idx.to(device) for crys_idx in graph[3]])\n",
    "            \n",
    "            xrd = torch.tensor(xrd, dtype = torch.float).to(device)\n",
    "            smiles = torch.from_numpy(smiles).to(device)\n",
    "\n",
    "            z_a = model_g(*input_graph_1)\n",
    "            z_b = model(xrd, smiles)\n",
    "\n",
    "            if norm == True:\n",
    "                z_a_norm = (z_a - torch.mean(z_a, axis = 0))/torch.std(z_a, axis = 0)\n",
    "                z_b_norm = (z_b - torch.mean(z_b, axis = 0))/torch.std(z_b, axis = 0)\n",
    "            else:\n",
    "                z_a_norm = z_a\n",
    "                z_b_norm = z_b\n",
    "            \n",
    "            valid_loss = loss(z_a_norm, z_b_norm)\n",
    "            val_ensemble.append(valid_loss.item())\n",
    "\n",
    "        val_history.append(np.mean(val_ensemble))\n",
    "        if np.mean(val_ensemble) < best_valid_loss:\n",
    "            best_valid_loss = np.mean(val_ensemble)\n",
    "            \n",
    "            #save the models here?\n",
    "            torch.save(model.state_dict(), os.path.join('SSL/pretrained/transformer', 'model_t.pth'))\n",
    "            torch.save(model_g.state_dict(), os.path.join('SSL/pretrained/cgcnn', 'model_g.pth'))\n",
    "\n",
    "    \n",
    "    loss_history.append(np.mean(loss_ensemble))\n",
    "    print(f'Ensembled Loss : {loss_history[-1]}, Val. Ensembled Loss : {val_history[-1]}')\n",
    "    print('###############################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves transformer\n",
    "torch.save(model, os.path.join('SSL/pretrained/transformer', f'pretrained_weights_{num_epoch}_{norm}.pth'))\n",
    "\n",
    "#saves CGCNN\n",
    "torch.save(model_g, os.path.join('SSL/pretrained/cgcnn', f'cgcnn_{num_epoch}_{norm}_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save loaded_dict state\n",
    "torch.save(model.state_dict(), os.path.join('SSL/pretrained/transformer', f'pretrained_dict_{num_epoch}_{norm}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history, label = 'Train')\n",
    "plt.plot(val_history, label = 'Val')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.savefig(os.path.join('SSL/figures', f'SSL_learning_curve_{num_epoch}_{norm}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not really learning - why? maybe compare to MOFormer and see how much their loss decreased by.\n",
    "#edit: issue fixed, initially set learning rate -> 0.0051 but it was too high (must have gotten stuck in a local minima somewhere) - it is learning now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
